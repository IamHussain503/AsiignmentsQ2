{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "colab": {
      "name": "Car_Price_Prediction_assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaukathussain/AsiignmentsQ2/blob/main/Car_Price_Prediction_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_HsWVrWvDNP"
      },
      "source": [
        "# Car Price Prediction::"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Neq61yUOvDNV"
      },
      "source": [
        "Download dataset from this link:\n",
        "\n",
        "https://www.kaggle.com/hellbuoy/car-price-prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "errs9eyZvDNW"
      },
      "source": [
        "# Problem Statement::"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92PLZp2kwKxv",
        "outputId": "995eb7f6-034b-4159-c332-d9eb34422f4c"
      },
      "source": [
        "# mount google drive in to your Colab enviornment\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvDEDSF3yS1S",
        "outputId": "eb5249fe-ce57-4830-89b7-48bdb72f22d9"
      },
      "source": [
        "cd /content/drive/MyDrive/AI_assignment/\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/AI_assignment\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCu6NRLVvDNX"
      },
      "source": [
        "A Chinese automobile company Geely Auto aspires to enter the US market by setting up their manufacturing unit there and producing cars locally to give competition to their US and European counterparts.\n",
        "\n",
        "They have contracted an automobile consulting company to understand the factors on which the pricing of cars depends. Specifically, they want to understand the factors affecting the pricing of cars in the American market, since those may be very different from the Chinese market. The company wants to know:\n",
        "\n",
        "Which variables are significant in predicting the price of a car\n",
        "How well those variables describe the price of a car\n",
        "Based on various market surveys, the consulting firm has gathered a large data set of different types of cars across the America market.\n",
        "\n",
        "# task::\n",
        "We are required to model the price of cars with the available independent variables. It will be used by the management to understand how exactly the prices vary with the independent variables. They can accordingly manipulate the design of the cars, the business strategy etc. to meet certain price levels. Further, the model will be a good way for management to understand the pricing dynamics of a new market."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-vI6CymvDNX"
      },
      "source": [
        "# WORKFLOW ::"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRvlK8RBvDNX"
      },
      "source": [
        "1.Load Data\n",
        "\n",
        "2.Check Missing Values ( If Exist ; Fill each record with mean of its feature )\n",
        "\n",
        "3.Split into 50% Training(Samples,Labels) , 30% Test(Samples,Labels) and 20% Validation Data(Samples,Labels).\n",
        "\n",
        "4.Model : input Layer (No. of features ), 3 hidden layers including 10,8,6 unit & Output Layer with activation function relu/tanh (check by experiment).\n",
        "\n",
        "5.Compilation Step (Note : Its a Regression problem , select loss , metrics according to it)\n",
        "6.Train the Model with Epochs (100) and validate it\n",
        "\n",
        "7.If the model gets overfit tune your model by changing the units , No. of layers , activation function , epochs , add dropout layer or add Regularizer according to the need .\n",
        "\n",
        "8.Evaluation Step\n",
        "\n",
        "9.Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duXMXXhZvDNY"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "car_data = pd.read_csv('./CarPrice_Assignment.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vd2sfUEUPRvi"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "-JRgNW0hzOVH",
        "outputId": "7c4607dd-841a-4340-bd1f-d74c3f4870a3"
      },
      "source": [
        "car_data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>car_ID</th>\n",
              "      <th>symboling</th>\n",
              "      <th>CarName</th>\n",
              "      <th>fueltype</th>\n",
              "      <th>aspiration</th>\n",
              "      <th>doornumber</th>\n",
              "      <th>carbody</th>\n",
              "      <th>drivewheel</th>\n",
              "      <th>enginelocation</th>\n",
              "      <th>wheelbase</th>\n",
              "      <th>carlength</th>\n",
              "      <th>carwidth</th>\n",
              "      <th>carheight</th>\n",
              "      <th>curbweight</th>\n",
              "      <th>enginetype</th>\n",
              "      <th>cylindernumber</th>\n",
              "      <th>enginesize</th>\n",
              "      <th>fuelsystem</th>\n",
              "      <th>boreratio</th>\n",
              "      <th>stroke</th>\n",
              "      <th>compressionratio</th>\n",
              "      <th>horsepower</th>\n",
              "      <th>peakrpm</th>\n",
              "      <th>citympg</th>\n",
              "      <th>highwaympg</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>alfa-romero giulia</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>two</td>\n",
              "      <td>convertible</td>\n",
              "      <td>rwd</td>\n",
              "      <td>front</td>\n",
              "      <td>88.6</td>\n",
              "      <td>168.8</td>\n",
              "      <td>64.1</td>\n",
              "      <td>48.8</td>\n",
              "      <td>2548</td>\n",
              "      <td>dohc</td>\n",
              "      <td>four</td>\n",
              "      <td>130</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>3.47</td>\n",
              "      <td>2.68</td>\n",
              "      <td>9.0</td>\n",
              "      <td>111</td>\n",
              "      <td>5000</td>\n",
              "      <td>21</td>\n",
              "      <td>27</td>\n",
              "      <td>13495.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>alfa-romero stelvio</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>two</td>\n",
              "      <td>convertible</td>\n",
              "      <td>rwd</td>\n",
              "      <td>front</td>\n",
              "      <td>88.6</td>\n",
              "      <td>168.8</td>\n",
              "      <td>64.1</td>\n",
              "      <td>48.8</td>\n",
              "      <td>2548</td>\n",
              "      <td>dohc</td>\n",
              "      <td>four</td>\n",
              "      <td>130</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>3.47</td>\n",
              "      <td>2.68</td>\n",
              "      <td>9.0</td>\n",
              "      <td>111</td>\n",
              "      <td>5000</td>\n",
              "      <td>21</td>\n",
              "      <td>27</td>\n",
              "      <td>16500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>alfa-romero Quadrifoglio</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>two</td>\n",
              "      <td>hatchback</td>\n",
              "      <td>rwd</td>\n",
              "      <td>front</td>\n",
              "      <td>94.5</td>\n",
              "      <td>171.2</td>\n",
              "      <td>65.5</td>\n",
              "      <td>52.4</td>\n",
              "      <td>2823</td>\n",
              "      <td>ohcv</td>\n",
              "      <td>six</td>\n",
              "      <td>152</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>2.68</td>\n",
              "      <td>3.47</td>\n",
              "      <td>9.0</td>\n",
              "      <td>154</td>\n",
              "      <td>5000</td>\n",
              "      <td>19</td>\n",
              "      <td>26</td>\n",
              "      <td>16500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>audi 100 ls</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>four</td>\n",
              "      <td>sedan</td>\n",
              "      <td>fwd</td>\n",
              "      <td>front</td>\n",
              "      <td>99.8</td>\n",
              "      <td>176.6</td>\n",
              "      <td>66.2</td>\n",
              "      <td>54.3</td>\n",
              "      <td>2337</td>\n",
              "      <td>ohc</td>\n",
              "      <td>four</td>\n",
              "      <td>109</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>3.19</td>\n",
              "      <td>3.40</td>\n",
              "      <td>10.0</td>\n",
              "      <td>102</td>\n",
              "      <td>5500</td>\n",
              "      <td>24</td>\n",
              "      <td>30</td>\n",
              "      <td>13950.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>audi 100ls</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>four</td>\n",
              "      <td>sedan</td>\n",
              "      <td>4wd</td>\n",
              "      <td>front</td>\n",
              "      <td>99.4</td>\n",
              "      <td>176.6</td>\n",
              "      <td>66.4</td>\n",
              "      <td>54.3</td>\n",
              "      <td>2824</td>\n",
              "      <td>ohc</td>\n",
              "      <td>five</td>\n",
              "      <td>136</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>3.19</td>\n",
              "      <td>3.40</td>\n",
              "      <td>8.0</td>\n",
              "      <td>115</td>\n",
              "      <td>5500</td>\n",
              "      <td>18</td>\n",
              "      <td>22</td>\n",
              "      <td>17450.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>201</td>\n",
              "      <td>-1</td>\n",
              "      <td>volvo 145e (sw)</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>four</td>\n",
              "      <td>sedan</td>\n",
              "      <td>rwd</td>\n",
              "      <td>front</td>\n",
              "      <td>109.1</td>\n",
              "      <td>188.8</td>\n",
              "      <td>68.9</td>\n",
              "      <td>55.5</td>\n",
              "      <td>2952</td>\n",
              "      <td>ohc</td>\n",
              "      <td>four</td>\n",
              "      <td>141</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>3.78</td>\n",
              "      <td>3.15</td>\n",
              "      <td>9.5</td>\n",
              "      <td>114</td>\n",
              "      <td>5400</td>\n",
              "      <td>23</td>\n",
              "      <td>28</td>\n",
              "      <td>16845.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201</th>\n",
              "      <td>202</td>\n",
              "      <td>-1</td>\n",
              "      <td>volvo 144ea</td>\n",
              "      <td>gas</td>\n",
              "      <td>turbo</td>\n",
              "      <td>four</td>\n",
              "      <td>sedan</td>\n",
              "      <td>rwd</td>\n",
              "      <td>front</td>\n",
              "      <td>109.1</td>\n",
              "      <td>188.8</td>\n",
              "      <td>68.8</td>\n",
              "      <td>55.5</td>\n",
              "      <td>3049</td>\n",
              "      <td>ohc</td>\n",
              "      <td>four</td>\n",
              "      <td>141</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>3.78</td>\n",
              "      <td>3.15</td>\n",
              "      <td>8.7</td>\n",
              "      <td>160</td>\n",
              "      <td>5300</td>\n",
              "      <td>19</td>\n",
              "      <td>25</td>\n",
              "      <td>19045.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>203</td>\n",
              "      <td>-1</td>\n",
              "      <td>volvo 244dl</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>four</td>\n",
              "      <td>sedan</td>\n",
              "      <td>rwd</td>\n",
              "      <td>front</td>\n",
              "      <td>109.1</td>\n",
              "      <td>188.8</td>\n",
              "      <td>68.9</td>\n",
              "      <td>55.5</td>\n",
              "      <td>3012</td>\n",
              "      <td>ohcv</td>\n",
              "      <td>six</td>\n",
              "      <td>173</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>3.58</td>\n",
              "      <td>2.87</td>\n",
              "      <td>8.8</td>\n",
              "      <td>134</td>\n",
              "      <td>5500</td>\n",
              "      <td>18</td>\n",
              "      <td>23</td>\n",
              "      <td>21485.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>204</td>\n",
              "      <td>-1</td>\n",
              "      <td>volvo 246</td>\n",
              "      <td>diesel</td>\n",
              "      <td>turbo</td>\n",
              "      <td>four</td>\n",
              "      <td>sedan</td>\n",
              "      <td>rwd</td>\n",
              "      <td>front</td>\n",
              "      <td>109.1</td>\n",
              "      <td>188.8</td>\n",
              "      <td>68.9</td>\n",
              "      <td>55.5</td>\n",
              "      <td>3217</td>\n",
              "      <td>ohc</td>\n",
              "      <td>six</td>\n",
              "      <td>145</td>\n",
              "      <td>idi</td>\n",
              "      <td>3.01</td>\n",
              "      <td>3.40</td>\n",
              "      <td>23.0</td>\n",
              "      <td>106</td>\n",
              "      <td>4800</td>\n",
              "      <td>26</td>\n",
              "      <td>27</td>\n",
              "      <td>22470.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>205</td>\n",
              "      <td>-1</td>\n",
              "      <td>volvo 264gl</td>\n",
              "      <td>gas</td>\n",
              "      <td>turbo</td>\n",
              "      <td>four</td>\n",
              "      <td>sedan</td>\n",
              "      <td>rwd</td>\n",
              "      <td>front</td>\n",
              "      <td>109.1</td>\n",
              "      <td>188.8</td>\n",
              "      <td>68.9</td>\n",
              "      <td>55.5</td>\n",
              "      <td>3062</td>\n",
              "      <td>ohc</td>\n",
              "      <td>four</td>\n",
              "      <td>141</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>3.78</td>\n",
              "      <td>3.15</td>\n",
              "      <td>9.5</td>\n",
              "      <td>114</td>\n",
              "      <td>5400</td>\n",
              "      <td>19</td>\n",
              "      <td>25</td>\n",
              "      <td>22625.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>205 rows × 26 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     car_ID  symboling                   CarName  ... citympg highwaympg    price\n",
              "0         1          3        alfa-romero giulia  ...      21         27  13495.0\n",
              "1         2          3       alfa-romero stelvio  ...      21         27  16500.0\n",
              "2         3          1  alfa-romero Quadrifoglio  ...      19         26  16500.0\n",
              "3         4          2               audi 100 ls  ...      24         30  13950.0\n",
              "4         5          2                audi 100ls  ...      18         22  17450.0\n",
              "..      ...        ...                       ...  ...     ...        ...      ...\n",
              "200     201         -1           volvo 145e (sw)  ...      23         28  16845.0\n",
              "201     202         -1               volvo 144ea  ...      19         25  19045.0\n",
              "202     203         -1               volvo 244dl  ...      18         23  21485.0\n",
              "203     204         -1                 volvo 246  ...      26         27  22470.0\n",
              "204     205         -1               volvo 264gl  ...      19         25  22625.0\n",
              "\n",
              "[205 rows x 26 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6NTeH-qvDNa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4513d213-5e32-4f84-cce3-5e742dc93662"
      },
      "source": [
        "#check if there are empty cells, if there are then row and column indexes will be returned where values are empty or missing\n",
        "np.where(car_data.applymap(lambda x: x ==''))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([], dtype=int64), array([], dtype=int64))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euCqFI3Y0l6h",
        "outputId": "fc66200b-e87b-4a07-8ba7-9892a37c901e"
      },
      "source": [
        "car_data.isnull().any()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "car_ID              False\n",
              "symboling           False\n",
              "CarName             False\n",
              "fueltype            False\n",
              "aspiration          False\n",
              "doornumber          False\n",
              "carbody             False\n",
              "drivewheel          False\n",
              "enginelocation      False\n",
              "wheelbase           False\n",
              "carlength           False\n",
              "carwidth            False\n",
              "carheight           False\n",
              "curbweight          False\n",
              "enginetype          False\n",
              "cylindernumber      False\n",
              "enginesize          False\n",
              "fuelsystem          False\n",
              "boreratio           False\n",
              "stroke              False\n",
              "compressionratio    False\n",
              "horsepower          False\n",
              "peakrpm             False\n",
              "citympg             False\n",
              "highwaympg          False\n",
              "price               False\n",
              "dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBJA5-NyX-zj"
      },
      "source": [
        "# drop useless column\n",
        "# car_data.drop(columns = ['car_ID','CarName'], inplace= True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6itRa1UvR67"
      },
      "source": [
        "#check if there are ambigous names or wrong strings here you will see 'audi 100 ls' and 'audi 100ls' have same \n",
        "#name but a space between '100 ls' will create an extra feature, which is not desireable, we will correct this name in next cell\n",
        "# car_data['CarName'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwZgj7IIvXRm"
      },
      "source": [
        "# correct the name error in audi 100 ls\n",
        "car_data.iloc[3,2] = 'audi 100ls'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1cCvWApvDNZ",
        "outputId": "e1ba570c-ad8b-405f-aa65-822c49a3a387"
      },
      "source": [
        "car_data.dtypes"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "car_ID                int64\n",
              "symboling             int64\n",
              "CarName              object\n",
              "fueltype             object\n",
              "aspiration           object\n",
              "doornumber           object\n",
              "carbody              object\n",
              "drivewheel           object\n",
              "enginelocation       object\n",
              "wheelbase           float64\n",
              "carlength           float64\n",
              "carwidth            float64\n",
              "carheight           float64\n",
              "curbweight            int64\n",
              "enginetype           object\n",
              "cylindernumber       object\n",
              "enginesize            int64\n",
              "fuelsystem           object\n",
              "boreratio           float64\n",
              "stroke              float64\n",
              "compressionratio    float64\n",
              "horsepower            int64\n",
              "peakrpm               int64\n",
              "citympg               int64\n",
              "highwaympg            int64\n",
              "price               float64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BN6vZOZr5EpP",
        "outputId": "aa8700ab-73e8-404b-c933-cc69ebb0db1d"
      },
      "source": [
        "# get columns so that we can use the column names for onehot encoding of catagorical featrues in next cell\n",
        "car_data.columns"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['car_ID', 'symboling', 'CarName', 'fueltype', 'aspiration',\n",
              "       'doornumber', 'carbody', 'drivewheel', 'enginelocation', 'wheelbase',\n",
              "       'carlength', 'carwidth', 'carheight', 'curbweight', 'enginetype',\n",
              "       'cylindernumber', 'enginesize', 'fuelsystem', 'boreratio', 'stroke',\n",
              "       'compressionratio', 'horsepower', 'peakrpm', 'citympg', 'highwaympg',\n",
              "       'price'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqvKX-JyvDNa"
      },
      "source": [
        "# onehot encode all catagorical columns\n",
        "final_car = pd.get_dummies(car_data, columns=['CarName','symboling','fueltype',\t'aspiration',\t'doornumber',\t'carbody',\t'drivewheel',\t'enginelocation',\t'enginetype',\t'cylindernumber',\t'fuelsystem'], drop_first = True)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgIZc8J6UswW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "56514041-a0be-46b6-f241-58d7d4bbd054"
      },
      "source": [
        "#check statistical data to see abnormal values and outliers\n",
        "final_car.describe()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>car_ID</th>\n",
              "      <th>wheelbase</th>\n",
              "      <th>carlength</th>\n",
              "      <th>carwidth</th>\n",
              "      <th>carheight</th>\n",
              "      <th>curbweight</th>\n",
              "      <th>enginesize</th>\n",
              "      <th>boreratio</th>\n",
              "      <th>stroke</th>\n",
              "      <th>compressionratio</th>\n",
              "      <th>horsepower</th>\n",
              "      <th>peakrpm</th>\n",
              "      <th>citympg</th>\n",
              "      <th>highwaympg</th>\n",
              "      <th>price</th>\n",
              "      <th>CarName_alfa-romero Quadrifoglio</th>\n",
              "      <th>CarName_alfa-romero giulia</th>\n",
              "      <th>CarName_alfa-romero stelvio</th>\n",
              "      <th>CarName_audi 100ls</th>\n",
              "      <th>CarName_audi 4000</th>\n",
              "      <th>CarName_audi 5000</th>\n",
              "      <th>CarName_audi 5000s (diesel)</th>\n",
              "      <th>CarName_audi fox</th>\n",
              "      <th>CarName_bmw 320i</th>\n",
              "      <th>CarName_bmw x1</th>\n",
              "      <th>CarName_bmw x3</th>\n",
              "      <th>CarName_bmw x4</th>\n",
              "      <th>CarName_bmw x5</th>\n",
              "      <th>CarName_bmw z4</th>\n",
              "      <th>CarName_buick century</th>\n",
              "      <th>CarName_buick century luxus (sw)</th>\n",
              "      <th>CarName_buick century special</th>\n",
              "      <th>CarName_buick electra 225 custom</th>\n",
              "      <th>CarName_buick opel isuzu deluxe</th>\n",
              "      <th>CarName_buick regal sport coupe (turbo)</th>\n",
              "      <th>CarName_buick skyhawk</th>\n",
              "      <th>CarName_buick skylark</th>\n",
              "      <th>CarName_chevrolet impala</th>\n",
              "      <th>CarName_chevrolet monte carlo</th>\n",
              "      <th>CarName_chevrolet vega 2300</th>\n",
              "      <th>...</th>\n",
              "      <th>CarName_volvo 245</th>\n",
              "      <th>CarName_volvo 246</th>\n",
              "      <th>CarName_volvo 264gl</th>\n",
              "      <th>CarName_volvo diesel</th>\n",
              "      <th>CarName_vw dasher</th>\n",
              "      <th>CarName_vw rabbit</th>\n",
              "      <th>symboling_-1</th>\n",
              "      <th>symboling_0</th>\n",
              "      <th>symboling_1</th>\n",
              "      <th>symboling_2</th>\n",
              "      <th>symboling_3</th>\n",
              "      <th>fueltype_gas</th>\n",
              "      <th>aspiration_turbo</th>\n",
              "      <th>doornumber_two</th>\n",
              "      <th>carbody_hardtop</th>\n",
              "      <th>carbody_hatchback</th>\n",
              "      <th>carbody_sedan</th>\n",
              "      <th>carbody_wagon</th>\n",
              "      <th>drivewheel_fwd</th>\n",
              "      <th>drivewheel_rwd</th>\n",
              "      <th>enginelocation_rear</th>\n",
              "      <th>enginetype_dohcv</th>\n",
              "      <th>enginetype_l</th>\n",
              "      <th>enginetype_ohc</th>\n",
              "      <th>enginetype_ohcf</th>\n",
              "      <th>enginetype_ohcv</th>\n",
              "      <th>enginetype_rotor</th>\n",
              "      <th>cylindernumber_five</th>\n",
              "      <th>cylindernumber_four</th>\n",
              "      <th>cylindernumber_six</th>\n",
              "      <th>cylindernumber_three</th>\n",
              "      <th>cylindernumber_twelve</th>\n",
              "      <th>cylindernumber_two</th>\n",
              "      <th>fuelsystem_2bbl</th>\n",
              "      <th>fuelsystem_4bbl</th>\n",
              "      <th>fuelsystem_idi</th>\n",
              "      <th>fuelsystem_mfi</th>\n",
              "      <th>fuelsystem_mpfi</th>\n",
              "      <th>fuelsystem_spdi</th>\n",
              "      <th>fuelsystem_spfi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>205.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>103.000000</td>\n",
              "      <td>98.756585</td>\n",
              "      <td>174.049268</td>\n",
              "      <td>65.907805</td>\n",
              "      <td>53.724878</td>\n",
              "      <td>2555.565854</td>\n",
              "      <td>126.907317</td>\n",
              "      <td>3.329756</td>\n",
              "      <td>3.255415</td>\n",
              "      <td>10.142537</td>\n",
              "      <td>104.117073</td>\n",
              "      <td>5125.121951</td>\n",
              "      <td>25.219512</td>\n",
              "      <td>30.751220</td>\n",
              "      <td>13276.710571</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.014634</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.009756</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.009756</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>...</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.009756</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.107317</td>\n",
              "      <td>0.326829</td>\n",
              "      <td>0.263415</td>\n",
              "      <td>0.156098</td>\n",
              "      <td>0.131707</td>\n",
              "      <td>0.902439</td>\n",
              "      <td>0.180488</td>\n",
              "      <td>0.439024</td>\n",
              "      <td>0.039024</td>\n",
              "      <td>0.341463</td>\n",
              "      <td>0.468293</td>\n",
              "      <td>0.121951</td>\n",
              "      <td>0.585366</td>\n",
              "      <td>0.370732</td>\n",
              "      <td>0.014634</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.058537</td>\n",
              "      <td>0.721951</td>\n",
              "      <td>0.073171</td>\n",
              "      <td>0.063415</td>\n",
              "      <td>0.019512</td>\n",
              "      <td>0.053659</td>\n",
              "      <td>0.775610</td>\n",
              "      <td>0.117073</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.019512</td>\n",
              "      <td>0.321951</td>\n",
              "      <td>0.014634</td>\n",
              "      <td>0.097561</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.458537</td>\n",
              "      <td>0.043902</td>\n",
              "      <td>0.004878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>59.322565</td>\n",
              "      <td>6.021776</td>\n",
              "      <td>12.337289</td>\n",
              "      <td>2.145204</td>\n",
              "      <td>2.443522</td>\n",
              "      <td>520.680204</td>\n",
              "      <td>41.642693</td>\n",
              "      <td>0.270844</td>\n",
              "      <td>0.313597</td>\n",
              "      <td>3.972040</td>\n",
              "      <td>39.544167</td>\n",
              "      <td>476.985643</td>\n",
              "      <td>6.542142</td>\n",
              "      <td>6.886443</td>\n",
              "      <td>7988.852332</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.120377</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.098531</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.098531</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>...</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.098531</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.310274</td>\n",
              "      <td>0.470202</td>\n",
              "      <td>0.441564</td>\n",
              "      <td>0.363836</td>\n",
              "      <td>0.339000</td>\n",
              "      <td>0.297446</td>\n",
              "      <td>0.385535</td>\n",
              "      <td>0.497483</td>\n",
              "      <td>0.194127</td>\n",
              "      <td>0.475361</td>\n",
              "      <td>0.500215</td>\n",
              "      <td>0.328031</td>\n",
              "      <td>0.493865</td>\n",
              "      <td>0.484183</td>\n",
              "      <td>0.120377</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.235330</td>\n",
              "      <td>0.449134</td>\n",
              "      <td>0.261054</td>\n",
              "      <td>0.244304</td>\n",
              "      <td>0.138655</td>\n",
              "      <td>0.225894</td>\n",
              "      <td>0.418201</td>\n",
              "      <td>0.322294</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.138655</td>\n",
              "      <td>0.468368</td>\n",
              "      <td>0.120377</td>\n",
              "      <td>0.297446</td>\n",
              "      <td>0.069843</td>\n",
              "      <td>0.499498</td>\n",
              "      <td>0.205380</td>\n",
              "      <td>0.069843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>86.600000</td>\n",
              "      <td>141.100000</td>\n",
              "      <td>60.300000</td>\n",
              "      <td>47.800000</td>\n",
              "      <td>1488.000000</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>2.540000</td>\n",
              "      <td>2.070000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>4150.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>5118.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>52.000000</td>\n",
              "      <td>94.500000</td>\n",
              "      <td>166.300000</td>\n",
              "      <td>64.100000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>2145.000000</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>3.150000</td>\n",
              "      <td>3.110000</td>\n",
              "      <td>8.600000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>4800.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>7788.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>103.000000</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>173.200000</td>\n",
              "      <td>65.500000</td>\n",
              "      <td>54.100000</td>\n",
              "      <td>2414.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>3.310000</td>\n",
              "      <td>3.290000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>5200.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>10295.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>154.000000</td>\n",
              "      <td>102.400000</td>\n",
              "      <td>183.100000</td>\n",
              "      <td>66.900000</td>\n",
              "      <td>55.500000</td>\n",
              "      <td>2935.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>3.580000</td>\n",
              "      <td>3.410000</td>\n",
              "      <td>9.400000</td>\n",
              "      <td>116.000000</td>\n",
              "      <td>5500.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>16503.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>205.000000</td>\n",
              "      <td>120.900000</td>\n",
              "      <td>208.100000</td>\n",
              "      <td>72.300000</td>\n",
              "      <td>59.800000</td>\n",
              "      <td>4066.000000</td>\n",
              "      <td>326.000000</td>\n",
              "      <td>3.940000</td>\n",
              "      <td>4.170000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>288.000000</td>\n",
              "      <td>6600.000000</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>45400.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 194 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           car_ID   wheelbase  ...  fuelsystem_spdi  fuelsystem_spfi\n",
              "count  205.000000  205.000000  ...       205.000000       205.000000\n",
              "mean   103.000000   98.756585  ...         0.043902         0.004878\n",
              "std     59.322565    6.021776  ...         0.205380         0.069843\n",
              "min      1.000000   86.600000  ...         0.000000         0.000000\n",
              "25%     52.000000   94.500000  ...         0.000000         0.000000\n",
              "50%    103.000000   97.000000  ...         0.000000         0.000000\n",
              "75%    154.000000  102.400000  ...         0.000000         0.000000\n",
              "max    205.000000  120.900000  ...         1.000000         1.000000\n",
              "\n",
              "[8 rows x 194 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_sikuUQAGD4"
      },
      "source": [
        "#initialize a seed value so that each time we can get the same random number sequence, it will help us  as a team\n",
        "# working on a common project to work on the same random data. Each new seed will generate a particular sequnce\n",
        "#of random number. You can choose any seed value here of your choice\n",
        "# 0.72 means we have taken 72% values for training set as we will make 72/4 = 18 rows of k fold validation data, where\n",
        "# value of k will be 4 when we compile and fit our model for validation\n",
        "np.random.seed(11111)\n",
        "msk = np.random.rand(len(final_car)) < 0.72\n",
        "train_total = final_car[msk]\n",
        "test_total = final_car[~msk]\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSjX5UckTu1_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92a89d05-8980-4750-8565-209f0058dacb"
      },
      "source": [
        "#check the length of our test and train datasets\n",
        "print(len(train_total))\n",
        "print(len(test_total))\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "141\n",
            "64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4njPsfOfLJP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "outputId": "078b9e69-920c-4a37-d46c-dfb825a68271"
      },
      "source": [
        "train_total.head(10)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>car_ID</th>\n",
              "      <th>wheelbase</th>\n",
              "      <th>carlength</th>\n",
              "      <th>carwidth</th>\n",
              "      <th>carheight</th>\n",
              "      <th>curbweight</th>\n",
              "      <th>enginesize</th>\n",
              "      <th>boreratio</th>\n",
              "      <th>stroke</th>\n",
              "      <th>compressionratio</th>\n",
              "      <th>horsepower</th>\n",
              "      <th>peakrpm</th>\n",
              "      <th>citympg</th>\n",
              "      <th>highwaympg</th>\n",
              "      <th>price</th>\n",
              "      <th>CarName_alfa-romero Quadrifoglio</th>\n",
              "      <th>CarName_alfa-romero giulia</th>\n",
              "      <th>CarName_alfa-romero stelvio</th>\n",
              "      <th>CarName_audi 100ls</th>\n",
              "      <th>CarName_audi 4000</th>\n",
              "      <th>CarName_audi 5000</th>\n",
              "      <th>CarName_audi 5000s (diesel)</th>\n",
              "      <th>CarName_audi fox</th>\n",
              "      <th>CarName_bmw 320i</th>\n",
              "      <th>CarName_bmw x1</th>\n",
              "      <th>CarName_bmw x3</th>\n",
              "      <th>CarName_bmw x4</th>\n",
              "      <th>CarName_bmw x5</th>\n",
              "      <th>CarName_bmw z4</th>\n",
              "      <th>CarName_buick century</th>\n",
              "      <th>CarName_buick century luxus (sw)</th>\n",
              "      <th>CarName_buick century special</th>\n",
              "      <th>CarName_buick electra 225 custom</th>\n",
              "      <th>CarName_buick opel isuzu deluxe</th>\n",
              "      <th>CarName_buick regal sport coupe (turbo)</th>\n",
              "      <th>CarName_buick skyhawk</th>\n",
              "      <th>CarName_buick skylark</th>\n",
              "      <th>CarName_chevrolet impala</th>\n",
              "      <th>CarName_chevrolet monte carlo</th>\n",
              "      <th>CarName_chevrolet vega 2300</th>\n",
              "      <th>...</th>\n",
              "      <th>CarName_volvo 245</th>\n",
              "      <th>CarName_volvo 246</th>\n",
              "      <th>CarName_volvo 264gl</th>\n",
              "      <th>CarName_volvo diesel</th>\n",
              "      <th>CarName_vw dasher</th>\n",
              "      <th>CarName_vw rabbit</th>\n",
              "      <th>symboling_-1</th>\n",
              "      <th>symboling_0</th>\n",
              "      <th>symboling_1</th>\n",
              "      <th>symboling_2</th>\n",
              "      <th>symboling_3</th>\n",
              "      <th>fueltype_gas</th>\n",
              "      <th>aspiration_turbo</th>\n",
              "      <th>doornumber_two</th>\n",
              "      <th>carbody_hardtop</th>\n",
              "      <th>carbody_hatchback</th>\n",
              "      <th>carbody_sedan</th>\n",
              "      <th>carbody_wagon</th>\n",
              "      <th>drivewheel_fwd</th>\n",
              "      <th>drivewheel_rwd</th>\n",
              "      <th>enginelocation_rear</th>\n",
              "      <th>enginetype_dohcv</th>\n",
              "      <th>enginetype_l</th>\n",
              "      <th>enginetype_ohc</th>\n",
              "      <th>enginetype_ohcf</th>\n",
              "      <th>enginetype_ohcv</th>\n",
              "      <th>enginetype_rotor</th>\n",
              "      <th>cylindernumber_five</th>\n",
              "      <th>cylindernumber_four</th>\n",
              "      <th>cylindernumber_six</th>\n",
              "      <th>cylindernumber_three</th>\n",
              "      <th>cylindernumber_twelve</th>\n",
              "      <th>cylindernumber_two</th>\n",
              "      <th>fuelsystem_2bbl</th>\n",
              "      <th>fuelsystem_4bbl</th>\n",
              "      <th>fuelsystem_idi</th>\n",
              "      <th>fuelsystem_mfi</th>\n",
              "      <th>fuelsystem_mpfi</th>\n",
              "      <th>fuelsystem_spdi</th>\n",
              "      <th>fuelsystem_spfi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>88.6</td>\n",
              "      <td>168.8</td>\n",
              "      <td>64.1</td>\n",
              "      <td>48.8</td>\n",
              "      <td>2548</td>\n",
              "      <td>130</td>\n",
              "      <td>3.47</td>\n",
              "      <td>2.68</td>\n",
              "      <td>9.0</td>\n",
              "      <td>111</td>\n",
              "      <td>5000</td>\n",
              "      <td>21</td>\n",
              "      <td>27</td>\n",
              "      <td>16500.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>94.5</td>\n",
              "      <td>171.2</td>\n",
              "      <td>65.5</td>\n",
              "      <td>52.4</td>\n",
              "      <td>2823</td>\n",
              "      <td>152</td>\n",
              "      <td>2.68</td>\n",
              "      <td>3.47</td>\n",
              "      <td>9.0</td>\n",
              "      <td>154</td>\n",
              "      <td>5000</td>\n",
              "      <td>19</td>\n",
              "      <td>26</td>\n",
              "      <td>16500.000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>99.8</td>\n",
              "      <td>176.6</td>\n",
              "      <td>66.2</td>\n",
              "      <td>54.3</td>\n",
              "      <td>2337</td>\n",
              "      <td>109</td>\n",
              "      <td>3.19</td>\n",
              "      <td>3.40</td>\n",
              "      <td>10.0</td>\n",
              "      <td>102</td>\n",
              "      <td>5500</td>\n",
              "      <td>24</td>\n",
              "      <td>30</td>\n",
              "      <td>13950.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>99.4</td>\n",
              "      <td>176.6</td>\n",
              "      <td>66.4</td>\n",
              "      <td>54.3</td>\n",
              "      <td>2824</td>\n",
              "      <td>136</td>\n",
              "      <td>3.19</td>\n",
              "      <td>3.40</td>\n",
              "      <td>8.0</td>\n",
              "      <td>115</td>\n",
              "      <td>5500</td>\n",
              "      <td>18</td>\n",
              "      <td>22</td>\n",
              "      <td>17450.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>99.8</td>\n",
              "      <td>177.3</td>\n",
              "      <td>66.3</td>\n",
              "      <td>53.1</td>\n",
              "      <td>2507</td>\n",
              "      <td>136</td>\n",
              "      <td>3.19</td>\n",
              "      <td>3.40</td>\n",
              "      <td>8.5</td>\n",
              "      <td>110</td>\n",
              "      <td>5500</td>\n",
              "      <td>19</td>\n",
              "      <td>25</td>\n",
              "      <td>15250.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>105.8</td>\n",
              "      <td>192.7</td>\n",
              "      <td>71.4</td>\n",
              "      <td>55.7</td>\n",
              "      <td>2844</td>\n",
              "      <td>136</td>\n",
              "      <td>3.19</td>\n",
              "      <td>3.40</td>\n",
              "      <td>8.5</td>\n",
              "      <td>110</td>\n",
              "      <td>5500</td>\n",
              "      <td>19</td>\n",
              "      <td>25</td>\n",
              "      <td>17710.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>105.8</td>\n",
              "      <td>192.7</td>\n",
              "      <td>71.4</td>\n",
              "      <td>55.7</td>\n",
              "      <td>2954</td>\n",
              "      <td>136</td>\n",
              "      <td>3.19</td>\n",
              "      <td>3.40</td>\n",
              "      <td>8.5</td>\n",
              "      <td>110</td>\n",
              "      <td>5500</td>\n",
              "      <td>19</td>\n",
              "      <td>25</td>\n",
              "      <td>18920.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>105.8</td>\n",
              "      <td>192.7</td>\n",
              "      <td>71.4</td>\n",
              "      <td>55.9</td>\n",
              "      <td>3086</td>\n",
              "      <td>131</td>\n",
              "      <td>3.13</td>\n",
              "      <td>3.40</td>\n",
              "      <td>8.3</td>\n",
              "      <td>140</td>\n",
              "      <td>5500</td>\n",
              "      <td>17</td>\n",
              "      <td>20</td>\n",
              "      <td>23875.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>99.5</td>\n",
              "      <td>178.2</td>\n",
              "      <td>67.9</td>\n",
              "      <td>52.0</td>\n",
              "      <td>3053</td>\n",
              "      <td>131</td>\n",
              "      <td>3.13</td>\n",
              "      <td>3.40</td>\n",
              "      <td>7.0</td>\n",
              "      <td>160</td>\n",
              "      <td>5500</td>\n",
              "      <td>16</td>\n",
              "      <td>22</td>\n",
              "      <td>17859.167</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>101.2</td>\n",
              "      <td>176.8</td>\n",
              "      <td>64.8</td>\n",
              "      <td>54.3</td>\n",
              "      <td>2395</td>\n",
              "      <td>108</td>\n",
              "      <td>3.50</td>\n",
              "      <td>2.80</td>\n",
              "      <td>8.8</td>\n",
              "      <td>101</td>\n",
              "      <td>5800</td>\n",
              "      <td>23</td>\n",
              "      <td>29</td>\n",
              "      <td>16925.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 194 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    car_ID  wheelbase  ...  fuelsystem_spdi  fuelsystem_spfi\n",
              "1        2       88.6  ...                0                0\n",
              "2        3       94.5  ...                0                0\n",
              "3        4       99.8  ...                0                0\n",
              "4        5       99.4  ...                0                0\n",
              "5        6       99.8  ...                0                0\n",
              "6        7      105.8  ...                0                0\n",
              "7        8      105.8  ...                0                0\n",
              "8        9      105.8  ...                0                0\n",
              "9       10       99.5  ...                0                0\n",
              "11      12      101.2  ...                0                0\n",
              "\n",
              "[10 rows x 194 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeYOhn1Eiams",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "4658388c-90ea-49fa-c2a9-191f742065dd"
      },
      "source": [
        "# check statistical overview if there are some outliers and abnormal values\n",
        "train_total.describe()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>car_ID</th>\n",
              "      <th>wheelbase</th>\n",
              "      <th>carlength</th>\n",
              "      <th>carwidth</th>\n",
              "      <th>carheight</th>\n",
              "      <th>curbweight</th>\n",
              "      <th>enginesize</th>\n",
              "      <th>boreratio</th>\n",
              "      <th>stroke</th>\n",
              "      <th>compressionratio</th>\n",
              "      <th>horsepower</th>\n",
              "      <th>peakrpm</th>\n",
              "      <th>citympg</th>\n",
              "      <th>highwaympg</th>\n",
              "      <th>price</th>\n",
              "      <th>CarName_alfa-romero Quadrifoglio</th>\n",
              "      <th>CarName_alfa-romero giulia</th>\n",
              "      <th>CarName_alfa-romero stelvio</th>\n",
              "      <th>CarName_audi 100ls</th>\n",
              "      <th>CarName_audi 4000</th>\n",
              "      <th>CarName_audi 5000</th>\n",
              "      <th>CarName_audi 5000s (diesel)</th>\n",
              "      <th>CarName_audi fox</th>\n",
              "      <th>CarName_bmw 320i</th>\n",
              "      <th>CarName_bmw x1</th>\n",
              "      <th>CarName_bmw x3</th>\n",
              "      <th>CarName_bmw x4</th>\n",
              "      <th>CarName_bmw x5</th>\n",
              "      <th>CarName_bmw z4</th>\n",
              "      <th>CarName_buick century</th>\n",
              "      <th>CarName_buick century luxus (sw)</th>\n",
              "      <th>CarName_buick century special</th>\n",
              "      <th>CarName_buick electra 225 custom</th>\n",
              "      <th>CarName_buick opel isuzu deluxe</th>\n",
              "      <th>CarName_buick regal sport coupe (turbo)</th>\n",
              "      <th>CarName_buick skyhawk</th>\n",
              "      <th>CarName_buick skylark</th>\n",
              "      <th>CarName_chevrolet impala</th>\n",
              "      <th>CarName_chevrolet monte carlo</th>\n",
              "      <th>CarName_chevrolet vega 2300</th>\n",
              "      <th>...</th>\n",
              "      <th>CarName_volvo 245</th>\n",
              "      <th>CarName_volvo 246</th>\n",
              "      <th>CarName_volvo 264gl</th>\n",
              "      <th>CarName_volvo diesel</th>\n",
              "      <th>CarName_vw dasher</th>\n",
              "      <th>CarName_vw rabbit</th>\n",
              "      <th>symboling_-1</th>\n",
              "      <th>symboling_0</th>\n",
              "      <th>symboling_1</th>\n",
              "      <th>symboling_2</th>\n",
              "      <th>symboling_3</th>\n",
              "      <th>fueltype_gas</th>\n",
              "      <th>aspiration_turbo</th>\n",
              "      <th>doornumber_two</th>\n",
              "      <th>carbody_hardtop</th>\n",
              "      <th>carbody_hatchback</th>\n",
              "      <th>carbody_sedan</th>\n",
              "      <th>carbody_wagon</th>\n",
              "      <th>drivewheel_fwd</th>\n",
              "      <th>drivewheel_rwd</th>\n",
              "      <th>enginelocation_rear</th>\n",
              "      <th>enginetype_dohcv</th>\n",
              "      <th>enginetype_l</th>\n",
              "      <th>enginetype_ohc</th>\n",
              "      <th>enginetype_ohcf</th>\n",
              "      <th>enginetype_ohcv</th>\n",
              "      <th>enginetype_rotor</th>\n",
              "      <th>cylindernumber_five</th>\n",
              "      <th>cylindernumber_four</th>\n",
              "      <th>cylindernumber_six</th>\n",
              "      <th>cylindernumber_three</th>\n",
              "      <th>cylindernumber_twelve</th>\n",
              "      <th>cylindernumber_two</th>\n",
              "      <th>fuelsystem_2bbl</th>\n",
              "      <th>fuelsystem_4bbl</th>\n",
              "      <th>fuelsystem_idi</th>\n",
              "      <th>fuelsystem_mfi</th>\n",
              "      <th>fuelsystem_mpfi</th>\n",
              "      <th>fuelsystem_spdi</th>\n",
              "      <th>fuelsystem_spfi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.0</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.0</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.0</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.0</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.00000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.0</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.0</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>141.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>99.780142</td>\n",
              "      <td>98.692199</td>\n",
              "      <td>173.658156</td>\n",
              "      <td>65.875887</td>\n",
              "      <td>53.648227</td>\n",
              "      <td>2546.787234</td>\n",
              "      <td>125.666667</td>\n",
              "      <td>3.324184</td>\n",
              "      <td>3.256809</td>\n",
              "      <td>10.070355</td>\n",
              "      <td>103.702128</td>\n",
              "      <td>5143.971631</td>\n",
              "      <td>25.113475</td>\n",
              "      <td>30.581560</td>\n",
              "      <td>13379.132390</td>\n",
              "      <td>0.007092</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.007092</td>\n",
              "      <td>0.021277</td>\n",
              "      <td>0.007092</td>\n",
              "      <td>0.007092</td>\n",
              "      <td>0.007092</td>\n",
              "      <td>0.007092</td>\n",
              "      <td>0.007092</td>\n",
              "      <td>0.007092</td>\n",
              "      <td>0.014184</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.007092</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.007092</td>\n",
              "      <td>0.007092</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.007092</td>\n",
              "      <td>0.007092</td>\n",
              "      <td>0.007092</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.007092</td>\n",
              "      <td>0.007092</td>\n",
              "      <td>...</td>\n",
              "      <td>0.007092</td>\n",
              "      <td>0.007092</td>\n",
              "      <td>0.007092</td>\n",
              "      <td>0.007092</td>\n",
              "      <td>0.007092</td>\n",
              "      <td>0.007092</td>\n",
              "      <td>0.120567</td>\n",
              "      <td>0.304965</td>\n",
              "      <td>0.276596</td>\n",
              "      <td>0.156028</td>\n",
              "      <td>0.141844</td>\n",
              "      <td>0.907801</td>\n",
              "      <td>0.198582</td>\n",
              "      <td>0.446809</td>\n",
              "      <td>0.042553</td>\n",
              "      <td>0.347518</td>\n",
              "      <td>0.446809</td>\n",
              "      <td>0.12766</td>\n",
              "      <td>0.581560</td>\n",
              "      <td>0.361702</td>\n",
              "      <td>0.014184</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.049645</td>\n",
              "      <td>0.723404</td>\n",
              "      <td>0.078014</td>\n",
              "      <td>0.056738</td>\n",
              "      <td>0.028369</td>\n",
              "      <td>0.063830</td>\n",
              "      <td>0.765957</td>\n",
              "      <td>0.120567</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.007092</td>\n",
              "      <td>0.028369</td>\n",
              "      <td>0.326241</td>\n",
              "      <td>0.021277</td>\n",
              "      <td>0.092199</td>\n",
              "      <td>0.007092</td>\n",
              "      <td>0.453901</td>\n",
              "      <td>0.035461</td>\n",
              "      <td>0.007092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>59.881322</td>\n",
              "      <td>6.005665</td>\n",
              "      <td>12.320089</td>\n",
              "      <td>2.188604</td>\n",
              "      <td>2.508204</td>\n",
              "      <td>529.769152</td>\n",
              "      <td>41.733451</td>\n",
              "      <td>0.266123</td>\n",
              "      <td>0.296387</td>\n",
              "      <td>3.868579</td>\n",
              "      <td>38.424275</td>\n",
              "      <td>474.472458</td>\n",
              "      <td>6.509435</td>\n",
              "      <td>6.734937</td>\n",
              "      <td>8189.494568</td>\n",
              "      <td>0.084215</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.084215</td>\n",
              "      <td>0.144819</td>\n",
              "      <td>0.084215</td>\n",
              "      <td>0.084215</td>\n",
              "      <td>0.084215</td>\n",
              "      <td>0.084215</td>\n",
              "      <td>0.084215</td>\n",
              "      <td>0.084215</td>\n",
              "      <td>0.118672</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.084215</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.084215</td>\n",
              "      <td>0.084215</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.084215</td>\n",
              "      <td>0.084215</td>\n",
              "      <td>0.084215</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.084215</td>\n",
              "      <td>0.084215</td>\n",
              "      <td>...</td>\n",
              "      <td>0.084215</td>\n",
              "      <td>0.084215</td>\n",
              "      <td>0.084215</td>\n",
              "      <td>0.084215</td>\n",
              "      <td>0.084215</td>\n",
              "      <td>0.084215</td>\n",
              "      <td>0.326785</td>\n",
              "      <td>0.462034</td>\n",
              "      <td>0.448910</td>\n",
              "      <td>0.364176</td>\n",
              "      <td>0.350134</td>\n",
              "      <td>0.290337</td>\n",
              "      <td>0.400354</td>\n",
              "      <td>0.498935</td>\n",
              "      <td>0.202567</td>\n",
              "      <td>0.477879</td>\n",
              "      <td>0.498935</td>\n",
              "      <td>0.33490</td>\n",
              "      <td>0.495062</td>\n",
              "      <td>0.482206</td>\n",
              "      <td>0.118672</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.217986</td>\n",
              "      <td>0.448910</td>\n",
              "      <td>0.269150</td>\n",
              "      <td>0.232165</td>\n",
              "      <td>0.166616</td>\n",
              "      <td>0.245321</td>\n",
              "      <td>0.424908</td>\n",
              "      <td>0.326785</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.084215</td>\n",
              "      <td>0.166616</td>\n",
              "      <td>0.470508</td>\n",
              "      <td>0.144819</td>\n",
              "      <td>0.290337</td>\n",
              "      <td>0.084215</td>\n",
              "      <td>0.499645</td>\n",
              "      <td>0.185601</td>\n",
              "      <td>0.084215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>86.600000</td>\n",
              "      <td>144.600000</td>\n",
              "      <td>61.800000</td>\n",
              "      <td>47.800000</td>\n",
              "      <td>1713.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>2.680000</td>\n",
              "      <td>2.190000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>4150.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>5118.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>49.000000</td>\n",
              "      <td>94.500000</td>\n",
              "      <td>166.300000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>51.600000</td>\n",
              "      <td>2128.000000</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>3.150000</td>\n",
              "      <td>3.150000</td>\n",
              "      <td>8.500000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>4800.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>7689.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>98.000000</td>\n",
              "      <td>96.500000</td>\n",
              "      <td>172.400000</td>\n",
              "      <td>65.400000</td>\n",
              "      <td>53.900000</td>\n",
              "      <td>2410.000000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>3.310000</td>\n",
              "      <td>3.290000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>5200.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>10245.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>150.000000</td>\n",
              "      <td>102.400000</td>\n",
              "      <td>180.300000</td>\n",
              "      <td>66.600000</td>\n",
              "      <td>55.500000</td>\n",
              "      <td>2952.000000</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>3.580000</td>\n",
              "      <td>3.400000</td>\n",
              "      <td>9.400000</td>\n",
              "      <td>116.000000</td>\n",
              "      <td>5500.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>16695.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>205.000000</td>\n",
              "      <td>115.600000</td>\n",
              "      <td>202.600000</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>59.800000</td>\n",
              "      <td>4066.000000</td>\n",
              "      <td>326.000000</td>\n",
              "      <td>3.940000</td>\n",
              "      <td>4.170000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>262.000000</td>\n",
              "      <td>6600.000000</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>45400.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 194 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           car_ID   wheelbase  ...  fuelsystem_spdi  fuelsystem_spfi\n",
              "count  141.000000  141.000000  ...       141.000000       141.000000\n",
              "mean    99.780142   98.692199  ...         0.035461         0.007092\n",
              "std     59.881322    6.005665  ...         0.185601         0.084215\n",
              "min      2.000000   86.600000  ...         0.000000         0.000000\n",
              "25%     49.000000   94.500000  ...         0.000000         0.000000\n",
              "50%     98.000000   96.500000  ...         0.000000         0.000000\n",
              "75%    150.000000  102.400000  ...         0.000000         0.000000\n",
              "max    205.000000  115.600000  ...         1.000000         1.000000\n",
              "\n",
              "[8 rows x 194 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iwv0k5MXkjiU"
      },
      "source": [
        "print(train_total.dtypes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMVbWuxTzEUh"
      },
      "source": [
        "# get our price labels and store in another dataframe\n",
        "train_label = train_total.loc[:,'price']\n",
        "test_label = test_total.loc[:,'price']"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ok93gWC0V7RC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd3f8f75-3677-45fd-eba8-17cf88c68aff"
      },
      "source": [
        "train_label"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1      16500.0\n",
              "2      16500.0\n",
              "3      13950.0\n",
              "4      17450.0\n",
              "5      15250.0\n",
              "        ...   \n",
              "200    16845.0\n",
              "201    19045.0\n",
              "202    21485.0\n",
              "203    22470.0\n",
              "204    22625.0\n",
              "Name: price, Length: 141, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pj0hGliz6ld"
      },
      "source": [
        "# drop price from oroginal training and test dataset , as price is not needed there\n",
        "test_data= test_total.drop(columns = ['price'])\n",
        "train_data= train_total.drop(columns = ['price'])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uw8yz0e1RjS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac44c538-5645-4d7b-ef70-2a3cf9702e49"
      },
      "source": [
        "train_data.shape[1]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "193"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ic0-eZgDZjsV"
      },
      "source": [
        "train_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTXSdXZs5InD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1338ef3-c796-4025-9b54-f67171cead56"
      },
      "source": [
        "#get indices of the columns so that we can know how many columns we have to normalize, as catagorical columns which we\n",
        "# have added with onehot encoding, do not need to be normalized.. normalizing will be done in next cell\n",
        "{train_data.columns.get_loc(c): c for idx, c in enumerate(train_data.columns)}"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'car_ID',\n",
              " 1: 'wheelbase',\n",
              " 2: 'carlength',\n",
              " 3: 'carwidth',\n",
              " 4: 'carheight',\n",
              " 5: 'curbweight',\n",
              " 6: 'enginesize',\n",
              " 7: 'boreratio',\n",
              " 8: 'stroke',\n",
              " 9: 'compressionratio',\n",
              " 10: 'horsepower',\n",
              " 11: 'peakrpm',\n",
              " 12: 'citympg',\n",
              " 13: 'highwaympg',\n",
              " 14: 'CarName_alfa-romero Quadrifoglio',\n",
              " 15: 'CarName_alfa-romero giulia',\n",
              " 16: 'CarName_alfa-romero stelvio',\n",
              " 17: 'CarName_audi 100ls',\n",
              " 18: 'CarName_audi 4000',\n",
              " 19: 'CarName_audi 5000',\n",
              " 20: 'CarName_audi 5000s (diesel)',\n",
              " 21: 'CarName_audi fox',\n",
              " 22: 'CarName_bmw 320i',\n",
              " 23: 'CarName_bmw x1',\n",
              " 24: 'CarName_bmw x3',\n",
              " 25: 'CarName_bmw x4',\n",
              " 26: 'CarName_bmw x5',\n",
              " 27: 'CarName_bmw z4',\n",
              " 28: 'CarName_buick century',\n",
              " 29: 'CarName_buick century luxus (sw)',\n",
              " 30: 'CarName_buick century special',\n",
              " 31: 'CarName_buick electra 225 custom',\n",
              " 32: 'CarName_buick opel isuzu deluxe',\n",
              " 33: 'CarName_buick regal sport coupe (turbo)',\n",
              " 34: 'CarName_buick skyhawk',\n",
              " 35: 'CarName_buick skylark',\n",
              " 36: 'CarName_chevrolet impala',\n",
              " 37: 'CarName_chevrolet monte carlo',\n",
              " 38: 'CarName_chevrolet vega 2300',\n",
              " 39: 'CarName_dodge challenger se',\n",
              " 40: 'CarName_dodge colt (sw)',\n",
              " 41: 'CarName_dodge colt hardtop',\n",
              " 42: 'CarName_dodge coronet custom',\n",
              " 43: 'CarName_dodge coronet custom (sw)',\n",
              " 44: 'CarName_dodge d200',\n",
              " 45: 'CarName_dodge dart custom',\n",
              " 46: 'CarName_dodge monaco (sw)',\n",
              " 47: 'CarName_dodge rampage',\n",
              " 48: 'CarName_honda accord',\n",
              " 49: 'CarName_honda accord cvcc',\n",
              " 50: 'CarName_honda accord lx',\n",
              " 51: 'CarName_honda civic',\n",
              " 52: 'CarName_honda civic (auto)',\n",
              " 53: 'CarName_honda civic 1300',\n",
              " 54: 'CarName_honda civic 1500 gl',\n",
              " 55: 'CarName_honda civic cvcc',\n",
              " 56: 'CarName_honda prelude',\n",
              " 57: 'CarName_isuzu D-Max ',\n",
              " 58: 'CarName_isuzu D-Max V-Cross',\n",
              " 59: 'CarName_isuzu MU-X',\n",
              " 60: 'CarName_jaguar xf',\n",
              " 61: 'CarName_jaguar xj',\n",
              " 62: 'CarName_jaguar xk',\n",
              " 63: 'CarName_maxda glc deluxe',\n",
              " 64: 'CarName_maxda rx3',\n",
              " 65: 'CarName_mazda 626',\n",
              " 66: 'CarName_mazda glc',\n",
              " 67: 'CarName_mazda glc 4',\n",
              " 68: 'CarName_mazda glc custom',\n",
              " 69: 'CarName_mazda glc custom l',\n",
              " 70: 'CarName_mazda glc deluxe',\n",
              " 71: 'CarName_mazda rx-4',\n",
              " 72: 'CarName_mazda rx-7 gs',\n",
              " 73: 'CarName_mazda rx2 coupe',\n",
              " 74: 'CarName_mercury cougar',\n",
              " 75: 'CarName_mitsubishi g4',\n",
              " 76: 'CarName_mitsubishi lancer',\n",
              " 77: 'CarName_mitsubishi mirage',\n",
              " 78: 'CarName_mitsubishi mirage g4',\n",
              " 79: 'CarName_mitsubishi montero',\n",
              " 80: 'CarName_mitsubishi outlander',\n",
              " 81: 'CarName_mitsubishi pajero',\n",
              " 82: 'CarName_nissan clipper',\n",
              " 83: 'CarName_nissan dayz',\n",
              " 84: 'CarName_nissan fuga',\n",
              " 85: 'CarName_nissan gt-r',\n",
              " 86: 'CarName_nissan juke',\n",
              " 87: 'CarName_nissan kicks',\n",
              " 88: 'CarName_nissan latio',\n",
              " 89: 'CarName_nissan leaf',\n",
              " 90: 'CarName_nissan note',\n",
              " 91: 'CarName_nissan nv200',\n",
              " 92: 'CarName_nissan otti',\n",
              " 93: 'CarName_nissan rogue',\n",
              " 94: 'CarName_nissan teana',\n",
              " 95: 'CarName_nissan titan',\n",
              " 96: 'CarName_peugeot 304',\n",
              " 97: 'CarName_peugeot 504',\n",
              " 98: 'CarName_peugeot 504 (sw)',\n",
              " 99: 'CarName_peugeot 505s turbo diesel',\n",
              " 100: 'CarName_peugeot 604sl',\n",
              " 101: 'CarName_plymouth cricket',\n",
              " 102: 'CarName_plymouth duster',\n",
              " 103: 'CarName_plymouth fury gran sedan',\n",
              " 104: 'CarName_plymouth fury iii',\n",
              " 105: 'CarName_plymouth satellite custom (sw)',\n",
              " 106: 'CarName_plymouth valiant',\n",
              " 107: 'CarName_porcshce panamera',\n",
              " 108: 'CarName_porsche boxter',\n",
              " 109: 'CarName_porsche cayenne',\n",
              " 110: 'CarName_porsche macan',\n",
              " 111: 'CarName_renault 12tl',\n",
              " 112: 'CarName_renault 5 gtl',\n",
              " 113: 'CarName_saab 99e',\n",
              " 114: 'CarName_saab 99gle',\n",
              " 115: 'CarName_saab 99le',\n",
              " 116: 'CarName_subaru',\n",
              " 117: 'CarName_subaru baja',\n",
              " 118: 'CarName_subaru brz',\n",
              " 119: 'CarName_subaru dl',\n",
              " 120: 'CarName_subaru r1',\n",
              " 121: 'CarName_subaru r2',\n",
              " 122: 'CarName_subaru trezia',\n",
              " 123: 'CarName_subaru tribeca',\n",
              " 124: 'CarName_toyota carina',\n",
              " 125: 'CarName_toyota celica gt',\n",
              " 126: 'CarName_toyota celica gt liftback',\n",
              " 127: 'CarName_toyota corolla',\n",
              " 128: 'CarName_toyota corolla 1200',\n",
              " 129: 'CarName_toyota corolla 1600 (sw)',\n",
              " 130: 'CarName_toyota corolla liftback',\n",
              " 131: 'CarName_toyota corolla tercel',\n",
              " 132: 'CarName_toyota corona',\n",
              " 133: 'CarName_toyota corona hardtop',\n",
              " 134: 'CarName_toyota corona liftback',\n",
              " 135: 'CarName_toyota corona mark ii',\n",
              " 136: 'CarName_toyota cressida',\n",
              " 137: 'CarName_toyota mark ii',\n",
              " 138: 'CarName_toyota starlet',\n",
              " 139: 'CarName_toyota tercel',\n",
              " 140: 'CarName_toyouta tercel',\n",
              " 141: 'CarName_vokswagen rabbit',\n",
              " 142: 'CarName_volkswagen 1131 deluxe sedan',\n",
              " 143: 'CarName_volkswagen 411 (sw)',\n",
              " 144: 'CarName_volkswagen dasher',\n",
              " 145: 'CarName_volkswagen model 111',\n",
              " 146: 'CarName_volkswagen rabbit',\n",
              " 147: 'CarName_volkswagen rabbit custom',\n",
              " 148: 'CarName_volkswagen super beetle',\n",
              " 149: 'CarName_volkswagen type 3',\n",
              " 150: 'CarName_volvo 144ea',\n",
              " 151: 'CarName_volvo 145e (sw)',\n",
              " 152: 'CarName_volvo 244dl',\n",
              " 153: 'CarName_volvo 245',\n",
              " 154: 'CarName_volvo 246',\n",
              " 155: 'CarName_volvo 264gl',\n",
              " 156: 'CarName_volvo diesel',\n",
              " 157: 'CarName_vw dasher',\n",
              " 158: 'CarName_vw rabbit',\n",
              " 159: 'symboling_-1',\n",
              " 160: 'symboling_0',\n",
              " 161: 'symboling_1',\n",
              " 162: 'symboling_2',\n",
              " 163: 'symboling_3',\n",
              " 164: 'fueltype_gas',\n",
              " 165: 'aspiration_turbo',\n",
              " 166: 'doornumber_two',\n",
              " 167: 'carbody_hardtop',\n",
              " 168: 'carbody_hatchback',\n",
              " 169: 'carbody_sedan',\n",
              " 170: 'carbody_wagon',\n",
              " 171: 'drivewheel_fwd',\n",
              " 172: 'drivewheel_rwd',\n",
              " 173: 'enginelocation_rear',\n",
              " 174: 'enginetype_dohcv',\n",
              " 175: 'enginetype_l',\n",
              " 176: 'enginetype_ohc',\n",
              " 177: 'enginetype_ohcf',\n",
              " 178: 'enginetype_ohcv',\n",
              " 179: 'enginetype_rotor',\n",
              " 180: 'cylindernumber_five',\n",
              " 181: 'cylindernumber_four',\n",
              " 182: 'cylindernumber_six',\n",
              " 183: 'cylindernumber_three',\n",
              " 184: 'cylindernumber_twelve',\n",
              " 185: 'cylindernumber_two',\n",
              " 186: 'fuelsystem_2bbl',\n",
              " 187: 'fuelsystem_4bbl',\n",
              " 188: 'fuelsystem_idi',\n",
              " 189: 'fuelsystem_mfi',\n",
              " 190: 'fuelsystem_mpfi',\n",
              " 191: 'fuelsystem_spdi',\n",
              " 192: 'fuelsystem_spfi'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1h5vhggTyRyw"
      },
      "source": [
        "## we normalize data because data has big vlaues in decimal and it will worsen performance of our model, may overfit \n",
        "## or  we may face hardware resource high usage\n",
        "# we will apply the formula normalized_train_data = (train_data - mean)/ stadrad_deviation\n",
        "## firt take mean of training, then subtract mean from each value of the array slice train_data.iloc[:,0:13]\n",
        "mean = train_data.iloc[:,0:13].mean(axis=0) # taking the mean of \n",
        "train_data.iloc[:,0:13] -= mean\n",
        "std = train_data.iloc[:,0:13].std(axis=0)\n",
        "train_data.iloc[:,0:13] /= std\n",
        "test_data.iloc[:,0:13] -= mean\n",
        "test_data.iloc[:,0:13] /= std\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdXge3xhAyiN"
      },
      "source": [
        "# x = (y - z)/ std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZYfOs0cfaGE"
      },
      "source": [
        "mean_label = train_label.mean()\n",
        "train_label -= mean_label\n",
        "std_label = train_label.std()\n",
        "train_label /= std_label\n",
        "test_label -= mean_label\n",
        "test_label /= std_label\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mc7B1amLmsx"
      },
      "source": [
        "print(mean_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8uIRUHEw7g4"
      },
      "source": [
        "test_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwYKROqCyWwi"
      },
      "source": [
        "train_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejyRo91P9Klh"
      },
      "source": [
        "#store in numpy array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLTpt0qn-R5y"
      },
      "source": [
        "test = np.array(test_data.iloc[:])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ym52Tun-vhn"
      },
      "source": [
        "train = np.array(train_data.iloc[:])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnFGfxGn_d1b"
      },
      "source": [
        "test_l= np.array(test_label.astype('float32'))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kklQZ0za_qZb"
      },
      "source": [
        "train_l= np.array(train_label.astype('float32'))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVbXDcGe5cY2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc6ebd75-e522-4a22-ab64-717d2fa9cf31"
      },
      "source": [
        "train.shape\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(141, 193)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArLkQAzx9W0f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MS0mDY0d9y3Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mm416iVz953_"
      },
      "source": [
        "\n",
        "# Models section\n",
        "```\n",
        "#WE will configure different models here according to relu, tanh , regularization, dropout etc..\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqOJjh8n8fMU"
      },
      "source": [
        "# we are passing activation function as a parameter here so that we can call this function with tanh or relu while\n",
        "# fitting and training the model\n",
        "from keras import models\n",
        "from keras import layers\n",
        "def build_model(act):\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Dense(128, activation= act,input_shape=(train.shape[1],)))\n",
        "  model.add(layers.Dense(64, activation= act))\n",
        "  model.add(layers.Dense(32, activation= act))\n",
        "  model.add(layers.Dense(1))\n",
        "  model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "  return model"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKs2Axd19Rsx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "650def24-5366-4d9c-c132-22bb4f010af3"
      },
      "source": [
        "build_model('relu').summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 128)               24832     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 35,201\n",
            "Trainable params: 35,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShTLMMUPWE2E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c632830e-ad98-4412-9aaa-8f6a98a07028"
      },
      "source": [
        "build_model('tanh').summary()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 128)               24832     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 35,201\n",
            "Trainable params: 35,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLNbzXjKqGSw"
      },
      "source": [
        "# Regularized model\n",
        "from keras import regularizers\n",
        "def build_model_regular(act):\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Dense(10, activation= act,kernel_regularizer= regularizers.l1_l2(l1=0.001, l2=0.001),input_shape=(train.shape[1],)))\n",
        "  model.add(layers.Dense(8, activation= act,kernel_regularizer= regularizers.l1_l2(l1=0.001, l2=0.001)))\n",
        "  model.add(layers.Dense(6, activation= act,kernel_regularizer= regularizers.l1_l2(l1=0.001, l2=0.001)))\n",
        "  model.add(layers.Dense(1))\n",
        "  model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "  return model"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afnNh94NrncJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7cd3858-b484-42eb-d315-b6129b34a17d"
      },
      "source": [
        "build_model_regular('tanh').summary()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_8 (Dense)              (None, 10)                1940      \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 8)                 88        \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 6)                 54        \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 7         \n",
            "=================================================================\n",
            "Total params: 2,089\n",
            "Trainable params: 2,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKOI8TLD1SHd"
      },
      "source": [
        "# dropout model\n",
        "from keras import regularizers\n",
        "def build_model_drop(act):\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Dense(10, activation= act,input_shape=(train.shape[1],)))\n",
        "  model.add(layers.Dropout(0.1))\n",
        "  model.add(layers.Dense(8, activation= act))\n",
        "  model.add(layers.Dropout(0.1))\n",
        "  model.add(layers.Dense(6, activation= act))\n",
        "  model.add(layers.Dropout(0.1))\n",
        "  model.add(layers.Dense(1))\n",
        "  model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "  return model"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwAm7RMr_eMa"
      },
      "source": [
        "# K Fold validation section\n",
        "## here we will use len(train)//k to make 141//4 = 36 rows for validation in each validation test and collect the validation scores for relu , tanh , regularization , and dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTizsf6znpb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a631689a-b399-4a79-850e-80591d5ad5ac"
      },
      "source": [
        "#k fold validation with relu\n",
        "# 141/4\n",
        "import numpy as np\n",
        "k =  4\n",
        "num_val_samples = len(train) // k\n",
        "num_epochs = 100\n",
        "all_scores_relu = []\n",
        "for i in range(k):\n",
        "  print('processing fold #', i)\n",
        "  val_data = train[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "  val_targets = train_l[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "  partial_train_data = np.concatenate([train[:i * num_val_samples],train[(i + 1) * num_val_samples:]],  axis=0)\n",
        "  # print(partial_train_data)\n",
        "  partial_train_targets = np.concatenate([train_l[:i * num_val_samples],train_l[(i + 1) * num_val_samples:]],axis=0)\n",
        "  model = build_model('relu')\n",
        "  model.fit(partial_train_data, partial_train_targets,epochs=num_epochs, batch_size=1, verbose=0)\n",
        "  val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
        "  all_scores_relu.append(val_mae)\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing fold # 0\n",
            "processing fold # 1\n",
            "processing fold # 2\n",
            "processing fold # 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaXgBohaz4WI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f31a61e-122e-487e-a2f6-1f9131091b40"
      },
      "source": [
        "# 141/4\n",
        "#k fold validation with tanh\n",
        "import numpy as np\n",
        "k =  4\n",
        "num_val_samples = len(train) // k\n",
        "num_epochs = 100\n",
        "all_scores_tanh = []\n",
        "for i in range(k):\n",
        "  print('processing fold #', i)\n",
        "  val_data = train[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "  val_targets = train_l[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "  partial_train_data = np.concatenate([train[:i * num_val_samples],train[(i + 1) * num_val_samples:]],  axis=0)\n",
        "  # print(partial_train_data)\n",
        "  partial_train_targets = np.concatenate([train_l[:i * num_val_samples],train_l[(i + 1) * num_val_samples:]],axis=0)\n",
        "  model = build_model('tanh')\n",
        "  model.fit(partial_train_data, partial_train_targets,epochs=num_epochs, batch_size=1, verbose=0)\n",
        "  val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
        "  all_scores_tanh.append(val_mae)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing fold # 0\n",
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe01a297710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "processing fold # 1\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe02078f9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "processing fold # 2\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe01ff15b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "processing fold # 3\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe01fede050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SD6TuagJb54U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d42f90be-5033-4eb4-a821-5fad8e2fa42b"
      },
      "source": [
        "#k-fold validtion with regularization\n",
        "import numpy as np\n",
        "k =  4\n",
        "num_val_samples = len(train) // k\n",
        "num_epochs = 100\n",
        "all_scores_regular = []\n",
        "for i in range(k):\n",
        "  print('processing fold #', i)\n",
        "  val_data = train[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "  val_targets = train_l[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "  partial_train_data = np.concatenate([train[:i * num_val_samples],train[(i + 1) * num_val_samples:]],  axis=0)\n",
        "  # print(partial_train_data)\n",
        "  partial_train_targets = np.concatenate([train_l[:i * num_val_samples],train_l[(i + 1) * num_val_samples:]],axis=0)\n",
        "  model = build_model_regular('relu')\n",
        "  model.fit(partial_train_data, partial_train_targets,epochs=num_epochs, batch_size=1, verbose=0)\n",
        "  val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
        "  all_scores_regular.append(val_mae)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing fold # 0\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe01ab29440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "processing fold # 1\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe01b3f6b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "processing fold # 2\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe01985a680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "processing fold # 3\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe019615830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3ENBDAMrHtb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed64c388-6498-487b-94a6-8993927aa3f3"
      },
      "source": [
        "#k-fold validtion with dropout\n",
        "import numpy as np\n",
        "k =  4\n",
        "num_val_samples = len(train) // k\n",
        "num_epochs = 100\n",
        "all_scores_drop = []\n",
        "for i in range(k):\n",
        "  print('processing fold #', i)\n",
        "  val_data = train[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "  val_targets = train_l[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "  partial_train_data = np.concatenate([train[:i * num_val_samples],train[(i + 1) * num_val_samples:]],  axis=0)\n",
        "  # print(partial_train_data)\n",
        "  partial_train_targets = np.concatenate([train_l[:i * num_val_samples],train_l[(i + 1) * num_val_samples:]],axis=0)\n",
        "  model = build_model_drop('relu')\n",
        "  model.fit(partial_train_data, partial_train_targets,epochs=num_epochs, batch_size=1, verbose=1)\n",
        "  val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=1)\n",
        "  all_scores_drop.append(val_mae)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing fold # 0\n",
            "Epoch 1/100\n",
            "106/106 [==============================] - 1s 1ms/step - loss: 3.3924 - mae: 1.4655\n",
            "Epoch 2/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 1.1589 - mae: 0.7559\n",
            "Epoch 3/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.6663 - mae: 0.5322\n",
            "Epoch 4/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.5059 - mae: 0.4807\n",
            "Epoch 5/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.3276 - mae: 0.3765\n",
            "Epoch 6/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.4521 - mae: 0.4264\n",
            "Epoch 7/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.3901 - mae: 0.4006\n",
            "Epoch 8/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2860 - mae: 0.3859\n",
            "Epoch 9/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.3079 - mae: 0.3404\n",
            "Epoch 10/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2126 - mae: 0.3139\n",
            "Epoch 11/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2791 - mae: 0.3272\n",
            "Epoch 12/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.3098 - mae: 0.3968\n",
            "Epoch 13/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1610 - mae: 0.2579\n",
            "Epoch 14/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.4167 - mae: 0.3762\n",
            "Epoch 15/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2379 - mae: 0.3720\n",
            "Epoch 16/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1990 - mae: 0.3043\n",
            "Epoch 17/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1613 - mae: 0.2756\n",
            "Epoch 18/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2815 - mae: 0.3315\n",
            "Epoch 19/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0913 - mae: 0.2153\n",
            "Epoch 20/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.3466 - mae: 0.3736\n",
            "Epoch 21/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2750 - mae: 0.3732\n",
            "Epoch 22/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1883 - mae: 0.2700\n",
            "Epoch 23/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2158 - mae: 0.3408\n",
            "Epoch 24/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2299 - mae: 0.3230\n",
            "Epoch 25/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1518 - mae: 0.2853\n",
            "Epoch 26/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1275 - mae: 0.2599\n",
            "Epoch 27/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1431 - mae: 0.2282\n",
            "Epoch 28/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2821 - mae: 0.3030\n",
            "Epoch 29/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1306 - mae: 0.2468\n",
            "Epoch 30/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1427 - mae: 0.2461\n",
            "Epoch 31/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0722 - mae: 0.1972\n",
            "Epoch 32/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1085 - mae: 0.2223\n",
            "Epoch 33/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0985 - mae: 0.2152\n",
            "Epoch 34/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1042 - mae: 0.2231\n",
            "Epoch 35/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2320 - mae: 0.2548\n",
            "Epoch 36/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0923 - mae: 0.1993\n",
            "Epoch 37/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1426 - mae: 0.2263\n",
            "Epoch 38/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1986 - mae: 0.2608\n",
            "Epoch 39/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0878 - mae: 0.2032\n",
            "Epoch 40/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1066 - mae: 0.2168\n",
            "Epoch 41/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1654 - mae: 0.2575\n",
            "Epoch 42/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1448 - mae: 0.2261\n",
            "Epoch 43/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1998 - mae: 0.2550\n",
            "Epoch 44/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1791 - mae: 0.2793\n",
            "Epoch 45/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1309 - mae: 0.2016\n",
            "Epoch 46/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0703 - mae: 0.1724\n",
            "Epoch 47/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2075 - mae: 0.2449\n",
            "Epoch 48/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0578 - mae: 0.1778\n",
            "Epoch 49/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0851 - mae: 0.1692\n",
            "Epoch 50/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0730 - mae: 0.1724\n",
            "Epoch 51/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0960 - mae: 0.2302\n",
            "Epoch 52/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1771 - mae: 0.2509\n",
            "Epoch 53/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1089 - mae: 0.2102\n",
            "Epoch 54/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0873 - mae: 0.1780\n",
            "Epoch 55/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2245 - mae: 0.2835\n",
            "Epoch 56/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2252 - mae: 0.3017\n",
            "Epoch 57/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1283 - mae: 0.2268\n",
            "Epoch 58/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0925 - mae: 0.2077\n",
            "Epoch 59/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1119 - mae: 0.2071\n",
            "Epoch 60/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0883 - mae: 0.1817\n",
            "Epoch 61/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1207 - mae: 0.1957\n",
            "Epoch 62/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1037 - mae: 0.1970\n",
            "Epoch 63/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1944 - mae: 0.2450\n",
            "Epoch 64/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1240 - mae: 0.2078\n",
            "Epoch 65/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1644 - mae: 0.2257\n",
            "Epoch 66/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1795 - mae: 0.2276\n",
            "Epoch 67/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1133 - mae: 0.2088\n",
            "Epoch 68/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0847 - mae: 0.1987\n",
            "Epoch 69/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2169 - mae: 0.2401\n",
            "Epoch 70/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1085 - mae: 0.2145\n",
            "Epoch 71/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1104 - mae: 0.2013\n",
            "Epoch 72/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1258 - mae: 0.2195\n",
            "Epoch 73/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1035 - mae: 0.1968\n",
            "Epoch 74/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2302 - mae: 0.2587\n",
            "Epoch 75/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0846 - mae: 0.2016\n",
            "Epoch 76/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2789 - mae: 0.2684\n",
            "Epoch 77/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0851 - mae: 0.1827\n",
            "Epoch 78/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1272 - mae: 0.1872\n",
            "Epoch 79/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1670 - mae: 0.2244\n",
            "Epoch 80/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0513 - mae: 0.1464\n",
            "Epoch 81/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1199 - mae: 0.2253\n",
            "Epoch 82/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2137 - mae: 0.2354\n",
            "Epoch 83/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0592 - mae: 0.1469\n",
            "Epoch 84/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0486 - mae: 0.1388\n",
            "Epoch 85/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1212 - mae: 0.2043\n",
            "Epoch 86/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0999 - mae: 0.1852\n",
            "Epoch 87/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1556 - mae: 0.1837\n",
            "Epoch 88/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0668 - mae: 0.1541\n",
            "Epoch 89/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1157 - mae: 0.2291\n",
            "Epoch 90/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0839 - mae: 0.1954\n",
            "Epoch 91/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2642 - mae: 0.2684\n",
            "Epoch 92/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0645 - mae: 0.1598\n",
            "Epoch 93/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0817 - mae: 0.1533\n",
            "Epoch 94/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0496 - mae: 0.1496\n",
            "Epoch 95/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0745 - mae: 0.1574\n",
            "Epoch 96/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1626 - mae: 0.1983\n",
            "Epoch 97/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.1318\n",
            "Epoch 98/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0972 - mae: 0.1620\n",
            "Epoch 99/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1827 - mae: 0.2359\n",
            "Epoch 100/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0450 - mae: 0.1484\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe020881cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1749 - mae: 0.2801\n",
            "processing fold # 1\n",
            "Epoch 1/100\n",
            "106/106 [==============================] - 1s 1ms/step - loss: 0.6649 - mae: 0.6469\n",
            "Epoch 2/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.8754 - mae: 0.6333\n",
            "Epoch 3/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.6387 - mae: 0.5430\n",
            "Epoch 4/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.8893 - mae: 0.6501\n",
            "Epoch 5/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.6393 - mae: 0.5289\n",
            "Epoch 6/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.4034 - mae: 0.4327\n",
            "Epoch 7/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.4608 - mae: 0.4618\n",
            "Epoch 8/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.6282 - mae: 0.5077\n",
            "Epoch 9/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.6464 - mae: 0.5094\n",
            "Epoch 10/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.3409 - mae: 0.3555\n",
            "Epoch 11/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.7481 - mae: 0.5334\n",
            "Epoch 12/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.5393 - mae: 0.4986\n",
            "Epoch 13/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.4016 - mae: 0.4302\n",
            "Epoch 14/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.3448 - mae: 0.4095\n",
            "Epoch 15/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.5579 - mae: 0.4518\n",
            "Epoch 16/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.5925 - mae: 0.4581\n",
            "Epoch 17/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2266 - mae: 0.2993\n",
            "Epoch 18/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.4355 - mae: 0.4434\n",
            "Epoch 19/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2580 - mae: 0.3249\n",
            "Epoch 20/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.3506 - mae: 0.3625\n",
            "Epoch 21/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2641 - mae: 0.3490\n",
            "Epoch 22/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.3158 - mae: 0.3679\n",
            "Epoch 23/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.3623 - mae: 0.3733\n",
            "Epoch 24/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2905 - mae: 0.3499\n",
            "Epoch 25/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.3536 - mae: 0.3628\n",
            "Epoch 26/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2249 - mae: 0.3343\n",
            "Epoch 27/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2587 - mae: 0.3312\n",
            "Epoch 28/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2805 - mae: 0.3696\n",
            "Epoch 29/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1900 - mae: 0.3061\n",
            "Epoch 30/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.3536 - mae: 0.3809\n",
            "Epoch 31/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.3259 - mae: 0.3718\n",
            "Epoch 32/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2855 - mae: 0.3290\n",
            "Epoch 33/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1977 - mae: 0.2825\n",
            "Epoch 34/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2335 - mae: 0.3056\n",
            "Epoch 35/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2413 - mae: 0.2930\n",
            "Epoch 36/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1477 - mae: 0.2661\n",
            "Epoch 37/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1474 - mae: 0.2893\n",
            "Epoch 38/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1693 - mae: 0.2875\n",
            "Epoch 39/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2780 - mae: 0.3253\n",
            "Epoch 40/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2567 - mae: 0.2805\n",
            "Epoch 41/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2754 - mae: 0.3288\n",
            "Epoch 42/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1716 - mae: 0.2906\n",
            "Epoch 43/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1906 - mae: 0.2711\n",
            "Epoch 44/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2181 - mae: 0.2712\n",
            "Epoch 45/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.3941 - mae: 0.3353\n",
            "Epoch 46/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0883 - mae: 0.2063\n",
            "Epoch 47/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.4597 - mae: 0.3346\n",
            "Epoch 48/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1043 - mae: 0.2262\n",
            "Epoch 49/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1370 - mae: 0.2634\n",
            "Epoch 50/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1692 - mae: 0.2624\n",
            "Epoch 51/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1333 - mae: 0.2541\n",
            "Epoch 52/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1193 - mae: 0.2503\n",
            "Epoch 53/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1332 - mae: 0.2540\n",
            "Epoch 54/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1154 - mae: 0.2255\n",
            "Epoch 55/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1602 - mae: 0.2471\n",
            "Epoch 56/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1869 - mae: 0.2301\n",
            "Epoch 57/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1491 - mae: 0.2598\n",
            "Epoch 58/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1713 - mae: 0.2403\n",
            "Epoch 59/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2147 - mae: 0.2714\n",
            "Epoch 60/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1074 - mae: 0.1848\n",
            "Epoch 61/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0820 - mae: 0.1871\n",
            "Epoch 62/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2375 - mae: 0.2909\n",
            "Epoch 63/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0935 - mae: 0.2014\n",
            "Epoch 64/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2055 - mae: 0.2945\n",
            "Epoch 65/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.2107\n",
            "Epoch 66/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1597 - mae: 0.2099\n",
            "Epoch 67/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1371 - mae: 0.2432\n",
            "Epoch 68/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1074 - mae: 0.2376\n",
            "Epoch 69/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1730 - mae: 0.2591\n",
            "Epoch 70/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0855 - mae: 0.1994\n",
            "Epoch 71/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0559 - mae: 0.1743\n",
            "Epoch 72/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2533 - mae: 0.2637\n",
            "Epoch 73/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0974 - mae: 0.1893\n",
            "Epoch 74/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1244 - mae: 0.2049\n",
            "Epoch 75/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1009 - mae: 0.2252\n",
            "Epoch 76/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1187 - mae: 0.2295\n",
            "Epoch 77/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.3651 - mae: 0.2743\n",
            "Epoch 78/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2257 - mae: 0.2947\n",
            "Epoch 79/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.5268 - mae: 0.4018\n",
            "Epoch 80/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2026 - mae: 0.2488\n",
            "Epoch 81/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.4035 - mae: 0.3034\n",
            "Epoch 82/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1593 - mae: 0.2552\n",
            "Epoch 83/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0637 - mae: 0.1765\n",
            "Epoch 84/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1940 - mae: 0.2390\n",
            "Epoch 85/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1016 - mae: 0.1891\n",
            "Epoch 86/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1287 - mae: 0.2179\n",
            "Epoch 87/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1008 - mae: 0.1984\n",
            "Epoch 88/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0945 - mae: 0.1835\n",
            "Epoch 89/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.3696 - mae: 0.3077\n",
            "Epoch 90/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0990 - mae: 0.2282\n",
            "Epoch 91/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1932 - mae: 0.2242\n",
            "Epoch 92/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1492 - mae: 0.1956\n",
            "Epoch 93/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0694 - mae: 0.1571\n",
            "Epoch 94/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0585 - mae: 0.1551\n",
            "Epoch 95/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1187 - mae: 0.2239\n",
            "Epoch 96/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1573 - mae: 0.2302\n",
            "Epoch 97/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1172 - mae: 0.1934\n",
            "Epoch 98/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1231 - mae: 0.2380\n",
            "Epoch 99/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0668 - mae: 0.1773\n",
            "Epoch 100/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0956 - mae: 0.2003\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe01d7935f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2982 - mae: 0.3588\n",
            "processing fold # 2\n",
            "Epoch 1/100\n",
            "106/106 [==============================] - 1s 1ms/step - loss: 1.5510 - mae: 0.9732\n",
            "Epoch 2/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.8994 - mae: 0.6755\n",
            "Epoch 3/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.7077 - mae: 0.6230\n",
            "Epoch 4/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.5393 - mae: 0.5311\n",
            "Epoch 5/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.4775 - mae: 0.4959\n",
            "Epoch 6/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.3961 - mae: 0.4493\n",
            "Epoch 7/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2900 - mae: 0.3722\n",
            "Epoch 8/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.5424 - mae: 0.4062\n",
            "Epoch 9/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.4564 - mae: 0.4001\n",
            "Epoch 10/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2974 - mae: 0.3783\n",
            "Epoch 11/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2648 - mae: 0.3615\n",
            "Epoch 12/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.3540 - mae: 0.3851\n",
            "Epoch 13/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2213 - mae: 0.3328\n",
            "Epoch 14/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2947 - mae: 0.3332\n",
            "Epoch 15/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2716 - mae: 0.3359\n",
            "Epoch 16/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2057 - mae: 0.3186\n",
            "Epoch 17/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2437 - mae: 0.3335\n",
            "Epoch 18/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.3721 - mae: 0.3784\n",
            "Epoch 19/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1504 - mae: 0.2521\n",
            "Epoch 20/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.7304 - mae: 0.4004\n",
            "Epoch 21/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.5764 - mae: 0.3881\n",
            "Epoch 22/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1835 - mae: 0.2594\n",
            "Epoch 23/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2577 - mae: 0.3305\n",
            "Epoch 24/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2499 - mae: 0.3003\n",
            "Epoch 25/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1582 - mae: 0.2650\n",
            "Epoch 26/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2119 - mae: 0.3196\n",
            "Epoch 27/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1064 - mae: 0.2069\n",
            "Epoch 28/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2149 - mae: 0.2835\n",
            "Epoch 29/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2181 - mae: 0.2741\n",
            "Epoch 30/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1114 - mae: 0.2345\n",
            "Epoch 31/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1672 - mae: 0.2457\n",
            "Epoch 32/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1682 - mae: 0.2796\n",
            "Epoch 33/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1878 - mae: 0.2699\n",
            "Epoch 34/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2091 - mae: 0.2507\n",
            "Epoch 35/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2140 - mae: 0.2864\n",
            "Epoch 36/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0934 - mae: 0.2215\n",
            "Epoch 37/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2355 - mae: 0.3548\n",
            "Epoch 38/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1223 - mae: 0.2236\n",
            "Epoch 39/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.4299 - mae: 0.3595\n",
            "Epoch 40/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.3727 - mae: 0.2890\n",
            "Epoch 41/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1602 - mae: 0.2087\n",
            "Epoch 42/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1935 - mae: 0.2553\n",
            "Epoch 43/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2309 - mae: 0.2835\n",
            "Epoch 44/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1741 - mae: 0.2262\n",
            "Epoch 45/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2259 - mae: 0.2820\n",
            "Epoch 46/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1938 - mae: 0.2596\n",
            "Epoch 47/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1339 - mae: 0.2283\n",
            "Epoch 48/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2089 - mae: 0.2645\n",
            "Epoch 49/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1371 - mae: 0.2327\n",
            "Epoch 50/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1018 - mae: 0.2212\n",
            "Epoch 51/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2295 - mae: 0.2941\n",
            "Epoch 52/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2107 - mae: 0.3102\n",
            "Epoch 53/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2772 - mae: 0.3186\n",
            "Epoch 54/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2011 - mae: 0.2592\n",
            "Epoch 55/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1752 - mae: 0.2446\n",
            "Epoch 56/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1628 - mae: 0.2219\n",
            "Epoch 57/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1258 - mae: 0.2089\n",
            "Epoch 58/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1467 - mae: 0.2652\n",
            "Epoch 59/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2173 - mae: 0.2919\n",
            "Epoch 60/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2291 - mae: 0.2786\n",
            "Epoch 61/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0724 - mae: 0.1843\n",
            "Epoch 62/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2263 - mae: 0.2809\n",
            "Epoch 63/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0880 - mae: 0.1865\n",
            "Epoch 64/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0983 - mae: 0.1982\n",
            "Epoch 65/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1600 - mae: 0.2373\n",
            "Epoch 66/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1049 - mae: 0.2183\n",
            "Epoch 67/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0844 - mae: 0.1766\n",
            "Epoch 68/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0605 - mae: 0.1640\n",
            "Epoch 69/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1604 - mae: 0.2157\n",
            "Epoch 70/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1406 - mae: 0.1807\n",
            "Epoch 71/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1034 - mae: 0.1842\n",
            "Epoch 72/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0904 - mae: 0.1994\n",
            "Epoch 73/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1136 - mae: 0.1990\n",
            "Epoch 74/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0614 - mae: 0.1554\n",
            "Epoch 75/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1649 - mae: 0.2447\n",
            "Epoch 76/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1034 - mae: 0.1963\n",
            "Epoch 77/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1686 - mae: 0.2516\n",
            "Epoch 78/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0973 - mae: 0.1899\n",
            "Epoch 79/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0635 - mae: 0.1663\n",
            "Epoch 80/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0986 - mae: 0.2171\n",
            "Epoch 81/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2669 - mae: 0.2754\n",
            "Epoch 82/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1534 - mae: 0.2407\n",
            "Epoch 83/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0785 - mae: 0.1740\n",
            "Epoch 84/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1270 - mae: 0.2272\n",
            "Epoch 85/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1128 - mae: 0.2162\n",
            "Epoch 86/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1564 - mae: 0.2467\n",
            "Epoch 87/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1145 - mae: 0.1826\n",
            "Epoch 88/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1242 - mae: 0.2280\n",
            "Epoch 89/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1142 - mae: 0.2017\n",
            "Epoch 90/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1064 - mae: 0.2044\n",
            "Epoch 91/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1971 - mae: 0.1909\n",
            "Epoch 92/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1347 - mae: 0.2337\n",
            "Epoch 93/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0942 - mae: 0.1902\n",
            "Epoch 94/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0574 - mae: 0.1706\n",
            "Epoch 95/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1265 - mae: 0.1918\n",
            "Epoch 96/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0854 - mae: 0.1725\n",
            "Epoch 97/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1814 - mae: 0.2175\n",
            "Epoch 98/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1240 - mae: 0.2029\n",
            "Epoch 99/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0789 - mae: 0.1779\n",
            "Epoch 100/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0987 - mae: 0.2050\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe01fede680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3018 - mae: 0.3481\n",
            "processing fold # 3\n",
            "Epoch 1/100\n",
            "106/106 [==============================] - 1s 1ms/step - loss: 1.8525 - mae: 1.0251\n",
            "Epoch 2/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 1.6970 - mae: 0.9140\n",
            "Epoch 3/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 1.4561 - mae: 0.8282\n",
            "Epoch 4/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.9232 - mae: 0.5817\n",
            "Epoch 5/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.7546 - mae: 0.5381\n",
            "Epoch 6/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.5085 - mae: 0.4742\n",
            "Epoch 7/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.6278 - mae: 0.5355\n",
            "Epoch 8/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.3534 - mae: 0.3941\n",
            "Epoch 9/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.5151 - mae: 0.4620\n",
            "Epoch 10/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.4814 - mae: 0.4602\n",
            "Epoch 11/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.3745 - mae: 0.3980\n",
            "Epoch 12/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.4226 - mae: 0.4368\n",
            "Epoch 13/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.4723 - mae: 0.4982\n",
            "Epoch 14/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2762 - mae: 0.3695\n",
            "Epoch 15/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.3403 - mae: 0.3944\n",
            "Epoch 16/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2261 - mae: 0.3074\n",
            "Epoch 17/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.4275 - mae: 0.4548\n",
            "Epoch 18/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2196 - mae: 0.3269\n",
            "Epoch 19/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 1.1636 - mae: 0.6338\n",
            "Epoch 20/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2235 - mae: 0.3586\n",
            "Epoch 21/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2843 - mae: 0.3374\n",
            "Epoch 22/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.3111 - mae: 0.3214\n",
            "Epoch 23/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2032 - mae: 0.3266\n",
            "Epoch 24/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2832 - mae: 0.3254\n",
            "Epoch 25/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2347 - mae: 0.3131\n",
            "Epoch 26/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2191 - mae: 0.3132\n",
            "Epoch 27/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.3233 - mae: 0.3846\n",
            "Epoch 28/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2896 - mae: 0.3872\n",
            "Epoch 29/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2572 - mae: 0.3304\n",
            "Epoch 30/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.3666 - mae: 0.3730\n",
            "Epoch 31/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1897 - mae: 0.3111\n",
            "Epoch 32/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.4427 - mae: 0.3759\n",
            "Epoch 33/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2215 - mae: 0.3168\n",
            "Epoch 34/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2201 - mae: 0.3123\n",
            "Epoch 35/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.3507 - mae: 0.3553\n",
            "Epoch 36/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1529 - mae: 0.2839\n",
            "Epoch 37/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2667 - mae: 0.3474\n",
            "Epoch 38/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.3093 - mae: 0.3186\n",
            "Epoch 39/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2375 - mae: 0.3402\n",
            "Epoch 40/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1874 - mae: 0.2970\n",
            "Epoch 41/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1720 - mae: 0.2705\n",
            "Epoch 42/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.2553\n",
            "Epoch 43/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2245 - mae: 0.2739\n",
            "Epoch 44/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1393 - mae: 0.2667\n",
            "Epoch 45/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2062 - mae: 0.3116\n",
            "Epoch 46/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1923 - mae: 0.3017\n",
            "Epoch 47/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.5624 - mae: 0.4340\n",
            "Epoch 48/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1300 - mae: 0.2527\n",
            "Epoch 49/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.3696 - mae: 0.3880\n",
            "Epoch 50/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1033 - mae: 0.2318\n",
            "Epoch 51/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1249 - mae: 0.2651\n",
            "Epoch 52/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.4645 - mae: 0.3534\n",
            "Epoch 53/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2954 - mae: 0.3586\n",
            "Epoch 54/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0877 - mae: 0.2209\n",
            "Epoch 55/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.2624 - mae: 0.3552\n",
            "Epoch 56/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.3451 - mae: 0.3458\n",
            "Epoch 57/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1339 - mae: 0.2687\n",
            "Epoch 58/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1413 - mae: 0.2411\n",
            "Epoch 59/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2122 - mae: 0.2692\n",
            "Epoch 60/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1745 - mae: 0.2389\n",
            "Epoch 61/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1963 - mae: 0.3089\n",
            "Epoch 62/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2990 - mae: 0.3229\n",
            "Epoch 63/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1325 - mae: 0.2231\n",
            "Epoch 64/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1296 - mae: 0.2485\n",
            "Epoch 65/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1096 - mae: 0.2122\n",
            "Epoch 66/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1537 - mae: 0.2626\n",
            "Epoch 67/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2084 - mae: 0.2669\n",
            "Epoch 68/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.4650 - mae: 0.3493\n",
            "Epoch 69/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1576 - mae: 0.2545\n",
            "Epoch 70/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.2416 - mae: 0.2743\n",
            "Epoch 71/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1549 - mae: 0.2290\n",
            "Epoch 72/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.4552 - mae: 0.3404\n",
            "Epoch 73/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2255 - mae: 0.2897\n",
            "Epoch 74/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1052 - mae: 0.2297\n",
            "Epoch 75/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1684 - mae: 0.2725\n",
            "Epoch 76/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1822 - mae: 0.2593\n",
            "Epoch 77/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0868 - mae: 0.2248\n",
            "Epoch 78/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1806 - mae: 0.2880\n",
            "Epoch 79/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.2163 - mae: 0.2874\n",
            "Epoch 80/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1604 - mae: 0.2499\n",
            "Epoch 81/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2003 - mae: 0.2860\n",
            "Epoch 82/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2402 - mae: 0.3267\n",
            "Epoch 83/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1990 - mae: 0.2898\n",
            "Epoch 84/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2170 - mae: 0.3164\n",
            "Epoch 85/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2327 - mae: 0.2581\n",
            "Epoch 86/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1117 - mae: 0.2248\n",
            "Epoch 87/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.2412 - mae: 0.2928\n",
            "Epoch 88/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0972 - mae: 0.2006\n",
            "Epoch 89/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1029 - mae: 0.2053\n",
            "Epoch 90/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1411 - mae: 0.2502\n",
            "Epoch 91/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1746 - mae: 0.2629\n",
            "Epoch 92/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1217 - mae: 0.2345\n",
            "Epoch 93/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1017 - mae: 0.2157\n",
            "Epoch 94/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1269 - mae: 0.2357\n",
            "Epoch 95/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1242 - mae: 0.2211\n",
            "Epoch 96/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.2764 - mae: 0.2931\n",
            "Epoch 97/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1622 - mae: 0.2234\n",
            "Epoch 98/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1562 - mae: 0.2622\n",
            "Epoch 99/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.0968 - mae: 0.2077\n",
            "Epoch 100/100\n",
            "106/106 [==============================] - 0s 1ms/step - loss: 0.1751 - mae: 0.2365\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe01ff15c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0550 - mae: 0.1766\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSlCIMtT_Gfd"
      },
      "source": [
        "# Scores\n",
        "## here we will see scores of all model which we have saved in the list during each training in above section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "We_C7ivQsh8Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cffbe428-c550-4a5f-9130-aeee005762e7"
      },
      "source": [
        "all_scores_relu"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.29605168104171753,\n",
              " 0.3464253842830658,\n",
              " 0.32078930735588074,\n",
              " 0.30166512727737427]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1gBTB5DrDA9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2823d845-665b-415d-af67-a2b139c69317"
      },
      "source": [
        "all_scores_tanh"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3168669044971466,\n",
              " 0.2959102690219879,\n",
              " 0.42779138684272766,\n",
              " 0.1943533718585968]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf7O0WnN9bVF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b997e7b-1ec4-4aa3-f0e9-7ee9ca9ee345"
      },
      "source": [
        "all_scores_regular"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2374347746372223,\n",
              " 0.23026597499847412,\n",
              " 0.3932662010192871,\n",
              " 0.26214393973350525]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jB8LxbiI0cpx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40cd332b-5073-42e6-ed76-b58e3950de0a"
      },
      "source": [
        "all_scores_drop"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.28009334206581116,\n",
              " 0.35884472727775574,\n",
              " 0.34813186526298523,\n",
              " 0.17655833065509796]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNxMnoqoAYd-"
      },
      "source": [
        "# training on the training data\n",
        "## here we will call each model separately from Models section and train on the training data and evaluate on the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VORrpehRb7UR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55a78787-19d6-4f32-b082-58eb51d17643"
      },
      "source": [
        "\n",
        "model_tanh = build_model('tanh')\n",
        "model_tanh.fit(train, train_l,epochs= 100, batch_size=1, verbose=0)\n",
        "test_mse_score, test_mae_score = model_tanh.evaluate(test, test_l)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe0190cc4d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0926 - mae: 0.2298\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ttydi9BzUnf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8f85fdd-601b-4d44-eba8-d17b0f637e3d"
      },
      "source": [
        "model_relu = build_model('relu')\n",
        "model_relu.fit(train, train_l,epochs= 100, batch_size=1, verbose=0)\n",
        "test_mse_score, test_mae_score = model_relu.evaluate(test, test_l)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe0190cc9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0764 - mae: 0.2143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZFYcfHftNlY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46a244e9-7ce8-4198-8c51-502457f2ec33"
      },
      "source": [
        "model_regular = build_model_regular('relu')\n",
        "model_regular.fit(train, train_l,epochs= 100, batch_size=1, verbose=0)\n",
        "test_mse_score, test_mae_score = model_regular.evaluate(test, test_l)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe0190ccd40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1084 - mae: 0.2153\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELSZLSCb0g7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c0b5245-0e74-4f89-e5fc-1e1d96108938"
      },
      "source": [
        "model_drop = build_model_drop('relu')\n",
        "model_drop.fit(train, train_l,epochs= 100, batch_size=1, verbose=0)\n",
        "test_mse_score, test_mae_score = model_drop.evaluate(test, test_l)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe034ecf5f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0995 - mae: 0.2383\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TV42POJyA-Na"
      },
      "source": [
        "# Prediction Section\n",
        "## here we will predict our prices of our test dataset with each model which we have trained in training section\n",
        "## Note that here we will use the reverse process of Normalization to retrieve our values of price in thousand of dollars i.e. x = (y - mean)/ std ==>> we will calculate( y = x * std + mean) and then we will compare it with our target values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mua_UYVJ7YNd"
      },
      "source": [
        "def predict(model, m):\n",
        "  print(\" the Actual value Price was : {test_l[m]* std_label + mean_label} \" )\n",
        "  return(\" the Actual value Price was : {(model.predict(test[m:m+1].reshape(1,test.shape[1]))) * std_label + mean_label} \")\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofX9VqMVbhBC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6139a95-83fa-47e3-a3ef-bb31d7371e68"
      },
      "source": [
        "x_tanh = predict(model_tanh,35)\n",
        "x_tanh"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " the Actual value Price was : {}  12764.0000223715\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(' the Actual value Price was : {} ', array([[16887.615]], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Z0UyL_LOImw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7321cff8-ec47-4659-e1b8-d5c21bbf325c"
      },
      "source": [
        "x_relu = predict(model_relu,35)\n",
        "x_relu"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " the Actual value Price was : {}  12764.0000223715\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(' the Actual value Price was : {} ', array([[14179.614]], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlQRNOo0tb8J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b9e7f62-03d6-4e2e-bb25-8ac65a69c415"
      },
      "source": [
        "x_regular = predict(model_regular,50)\n",
        "x_regular"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " the Actual value Price was : {}  8449.000052446656\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(' the Actual value Price was : {} ', array([[11244.867]], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW5Y65pP0qET",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fd3ba94-658f-42f6-80e0-8c0bef5801ba"
      },
      "source": [
        "x_drop = predict(model_drop,30)\n",
        "x_drop"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " the Actual value Price was : {}  17198.999901526033\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(' the Actual value Price was : {} ', array([[17277.9]], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    }
  ]
}